{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "frcnn_resnet50.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuwwSbkMGUZI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "99498926-4362-4598-90d0-98965bf8acb3"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nsSYGa5GWV0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "37ab57eb-17b8-41e2-c25e-45848aea12d0"
      },
      "source": [
        "import json\n",
        "import random\n",
        "import pprint\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "from optparse import OptionParser\n",
        "import pickle\n",
        "import math\n",
        "import cv2\n",
        "import copy\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam, SGD, RMSprop\n",
        "from keras.layers import Flatten, Dense, Input, Conv2D, MaxPooling2D, Dropout, Add, Activation, ZeroPadding2D, Convolution2D\n",
        "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, TimeDistributed, AveragePooling2D\n",
        "from keras.engine.topology import get_source_inputs\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.objectives import categorical_crossentropy\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.utils import generic_utils\n",
        "from keras.engine import Layer, InputSpec\n",
        "from keras import initializers, regularizers\n",
        "\n",
        "class Config:\n",
        "\n",
        "\tdef __init__(self):\n",
        "\n",
        "\t\tself.verbose = True\n",
        "\t\tself.network = 'vgg'\n",
        "\t\tself.use_horizontal_flips = False\n",
        "\t\tself.use_vertical_flips = False\n",
        "\t\tself.rot_90 = False\n",
        "\n",
        "\t\tself.anchor_box_scales = [64, 128, 256, 512] \n",
        "\t\tself.anchor_box_ratios = [[1, 1], [1, 2], [2, 1]]\n",
        "\t\t\n",
        "\t\tself.im_size = 600\n",
        "\t\tself.img_channel_mean = [103.939, 116.779, 123.68]\n",
        "\t\tself.img_scaling_factor = 1.0\n",
        "\t\tself.num_rois = 4\n",
        "\t\tself.rpn_stride = 16\n",
        "\n",
        "\t\tself.balanced_classes = False\n",
        "\n",
        "\t\tself.std_scaling = 4.0\n",
        "\t\tself.classifier_regr_std = [8.0, 8.0, 4.0, 4.0]\n",
        "\n",
        "\t\tself.rpn_min_overlap = 0.3\n",
        "\t\tself.rpn_max_overlap = 0.7\n",
        "\n",
        "\t\tself.classifier_min_overlap = 0.1\n",
        "\t\tself.classifier_max_overlap = 0.5\n",
        "\t\tself.class_mapping = None\n",
        "\n",
        "\t\tself.model_path = None\n",
        "\n",
        "def get_data(basePath = '/content/drive/My Drive/Colab Notebooks/'):\n",
        "    all_imgs = {}\n",
        "    classes_count = {}\n",
        "    class_mapping = {}\n",
        "\n",
        "    with open(basePath + \"dataInfo.json\",'r') as file:\n",
        "        all_imgs = json.load(fp = file)\n",
        "    with open(basePath + \"classes_count.json\",'r') as file:\n",
        "        classes_count = json.load(fp = file)\n",
        "    with open(basePath + \"class_mapping.json\",'r') as file:\n",
        "        class_mapping = json.load(fp = file)\n",
        "    \n",
        "    all_data = []\n",
        "    for key in all_imgs:\n",
        "        all_data.append(all_imgs[key])\n",
        "\t\t\t\n",
        "    return all_data, classes_count, class_mapping"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcSmz9pqGYjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def union(au, bu, area_intersection):\n",
        "\tarea_a = (au[2] - au[0]) * (au[3] - au[1])\n",
        "\tarea_b = (bu[2] - bu[0]) * (bu[3] - bu[1])\n",
        "\tarea_union = area_a + area_b - area_intersection\n",
        "\treturn area_union\n",
        "\n",
        "\n",
        "def intersection(ai, bi):\n",
        "\tx = max(ai[0], bi[0])\n",
        "\ty = max(ai[1], bi[1])\n",
        "\tw = min(ai[2], bi[2]) - x\n",
        "\th = min(ai[3], bi[3]) - y\n",
        "\tif w < 0 or h < 0:\n",
        "\t\treturn 0\n",
        "\treturn w*h\n",
        "\n",
        "\n",
        "def iou(a, b):\n",
        "\n",
        "\tif a[0] >= a[2] or a[1] >= a[3] or b[0] >= b[2] or b[1] >= b[3]:\n",
        "\t\treturn 0.0\n",
        "\n",
        "\tarea_i = intersection(a, b)\n",
        "\tarea_u = union(a, b, area_i)\n",
        "\n",
        "\treturn float(area_i) / float(area_u + 1e-6)\n",
        "\n",
        "def calc_rpn(C, img_data, width, height, resized_width, resized_height, img_length_calc_function):\n",
        "\t\n",
        "\tdownscale = float(C.rpn_stride) \n",
        "\tanchor_sizes = C.anchor_box_scales   \n",
        "\tanchor_ratios = C.anchor_box_ratios  \n",
        "\tnum_anchors = len(anchor_sizes) * len(anchor_ratios) \n",
        "\n",
        "\t(output_width, output_height) = img_length_calc_function(resized_width, resized_height)\n",
        "\n",
        "\tn_anchratios = len(anchor_ratios)    \n",
        "\t\n",
        "\ty_rpn_overlap = np.zeros((output_height, output_width, num_anchors))\n",
        "\ty_is_box_valid = np.zeros((output_height, output_width, num_anchors))\n",
        "\ty_rpn_regr = np.zeros((output_height, output_width, num_anchors * 4))\n",
        "\n",
        "\tnum_bboxes = len(img_data['bboxes'])\n",
        "\n",
        "\tnum_anchors_for_bbox = np.zeros(num_bboxes).astype(int)\n",
        "\tbest_anchor_for_bbox = -1*np.ones((num_bboxes, 4)).astype(int)\n",
        "\tbest_iou_for_bbox = np.zeros(num_bboxes).astype(np.float32)\n",
        "\tbest_x_for_bbox = np.zeros((num_bboxes, 4)).astype(int)\n",
        "\tbest_dx_for_bbox = np.zeros((num_bboxes, 4)).astype(np.float32)\n",
        "\n",
        "\tgta = np.zeros((num_bboxes, 4))\n",
        "\tfor bbox_num, bbox in enumerate(img_data['bboxes']):\n",
        "\t\tgta[bbox_num, 0] = bbox['x1'] * (resized_width / float(width))\n",
        "\t\tgta[bbox_num, 1] = bbox['x2'] * (resized_width / float(width))\n",
        "\t\tgta[bbox_num, 2] = bbox['y1'] * (resized_height / float(height))\n",
        "\t\tgta[bbox_num, 3] = bbox['y2'] * (resized_height / float(height))\n",
        "\n",
        "\tfor anchor_size_idx in range(len(anchor_sizes)):\n",
        "\t\tfor anchor_ratio_idx in range(n_anchratios):\n",
        "\t\t\tanchor_x = anchor_sizes[anchor_size_idx] * anchor_ratios[anchor_ratio_idx][0]\n",
        "\t\t\tanchor_y = anchor_sizes[anchor_size_idx] * anchor_ratios[anchor_ratio_idx][1]\t\n",
        "\t\t\t\n",
        "\t\t\tfor ix in range(output_width):\t\t\t\t\t\n",
        "\t\t\n",
        "\t\t\t\tx1_anc = downscale * (ix + 0.5) - anchor_x / 2\n",
        "\t\t\t\tx2_anc = downscale * (ix + 0.5) + anchor_x / 2\t\n",
        "\t\t\t\t\t\t\t\n",
        "\t\t\t\tif x1_anc < 0 or x2_anc > resized_width:\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\t\t\n",
        "\t\t\t\tfor jy in range(output_height):\n",
        "\t\t\t\t\ty1_anc = downscale * (jy + 0.5) - anchor_y / 2\n",
        "\t\t\t\t\ty2_anc = downscale * (jy + 0.5) + anchor_y / 2\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\tif y1_anc < 0 or y2_anc > resized_height:\n",
        "\t\t\t\t\t\tcontinue\n",
        "\n",
        "\t\t\t\t\tbbox_type = 'neg'\n",
        "\t\t\t\t\tbest_iou_for_loc = 0.0\n",
        "\n",
        "\t\t\t\t\tfor bbox_num in range(num_bboxes):\n",
        "\t\t\t\t\t\tcurr_iou = iou([gta[bbox_num, 0], gta[bbox_num, 2], gta[bbox_num, 1], gta[bbox_num, 3]], [x1_anc, y1_anc, x2_anc, y2_anc])\n",
        "\t\t\t\t\t\tif curr_iou > best_iou_for_bbox[bbox_num] or curr_iou > C.rpn_max_overlap:\n",
        "\t\t\t\t\t\t\tcx = (gta[bbox_num, 0] + gta[bbox_num, 1]) / 2.0\n",
        "\t\t\t\t\t\t\tcy = (gta[bbox_num, 2] + gta[bbox_num, 3]) / 2.0\n",
        "\t\t\t\t\t\t\tcxa = (x1_anc + x2_anc)/2.0\n",
        "\t\t\t\t\t\t\tcya = (y1_anc + y2_anc)/2.0\n",
        "\n",
        "\t\t\t\t\t\t\ttx = (cx - cxa) / (x2_anc - x1_anc)\n",
        "\t\t\t\t\t\t\tty = (cy - cya) / (y2_anc - y1_anc)\n",
        "\t\t\t\t\t\t\ttw = np.log((gta[bbox_num, 1] - gta[bbox_num, 0]) / (x2_anc - x1_anc))\n",
        "\t\t\t\t\t\t\tth = np.log((gta[bbox_num, 3] - gta[bbox_num, 2]) / (y2_anc - y1_anc))\n",
        "\t\t\t\t\t\t\n",
        "\t\t\t\t\t\tif img_data['bboxes'][bbox_num]['class'] != 'bg':\n",
        "\t\t\t\t\t\t\tif curr_iou > best_iou_for_bbox[bbox_num]:\n",
        "\t\t\t\t\t\t\t\tbest_anchor_for_bbox[bbox_num] = [jy, ix, anchor_ratio_idx, anchor_size_idx]\n",
        "\t\t\t\t\t\t\t\tbest_iou_for_bbox[bbox_num] = curr_iou\n",
        "\t\t\t\t\t\t\t\tbest_x_for_bbox[bbox_num,:] = [x1_anc, x2_anc, y1_anc, y2_anc]\n",
        "\t\t\t\t\t\t\t\tbest_dx_for_bbox[bbox_num,:] = [tx, ty, tw, th]\n",
        "\n",
        "\t\t\t\t\t\t\tif curr_iou > C.rpn_max_overlap:\n",
        "\t\t\t\t\t\t\t\tbbox_type = 'pos'\n",
        "\t\t\t\t\t\t\t\tnum_anchors_for_bbox[bbox_num] += 1\n",
        "\t\t\t\t\t\t\t\tif curr_iou > best_iou_for_loc:\n",
        "\t\t\t\t\t\t\t\t\tbest_iou_for_loc = curr_iou\n",
        "\t\t\t\t\t\t\t\t\tbest_regr = (tx, ty, tw, th)\n",
        "\t\t \n",
        "\t\t\t\t\t\t\tif C.rpn_min_overlap < curr_iou < C.rpn_max_overlap:\n",
        "\t\t\t\t\t\t\t\tif bbox_type != 'pos':\n",
        "\t\t\t\t\t\t\t\t\tbbox_type = 'neutral'\n",
        "\n",
        "\t\t\t\t\tif bbox_type == 'neg':\n",
        "\t\t\t\t\t\ty_is_box_valid[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 1\n",
        "\t\t\t\t\t\ty_rpn_overlap[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 0\n",
        "\t\t\t\t\telif bbox_type == 'neutral':\n",
        "\t\t\t\t\t\ty_is_box_valid[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 0\n",
        "\t\t\t\t\t\ty_rpn_overlap[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 0\n",
        "\t\t\t\t\telif bbox_type == 'pos':\n",
        "\t\t\t\t\t\ty_is_box_valid[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 1\n",
        "\t\t\t\t\t\ty_rpn_overlap[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 1\n",
        "\t\t\t\t\t\tstart = 4 * (anchor_ratio_idx + n_anchratios * anchor_size_idx)\n",
        "\t\t\t\t\t\ty_rpn_regr[jy, ix, start:start+4] = best_regr\n",
        "\n",
        "\tfor idx in range(num_anchors_for_bbox.shape[0]):\n",
        "\t\tif num_anchors_for_bbox[idx] == 0:\n",
        "\t\t\tif best_anchor_for_bbox[idx, 0] == -1:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\ty_is_box_valid[\n",
        "\t\t\t\tbest_anchor_for_bbox[idx,0], best_anchor_for_bbox[idx,1], best_anchor_for_bbox[idx,2] + n_anchratios *\n",
        "\t\t\t\tbest_anchor_for_bbox[idx,3]] = 1\n",
        "\t\t\ty_rpn_overlap[\n",
        "\t\t\t\tbest_anchor_for_bbox[idx,0], best_anchor_for_bbox[idx,1], best_anchor_for_bbox[idx,2] + n_anchratios *\n",
        "\t\t\t\tbest_anchor_for_bbox[idx,3]] = 1\n",
        "\t\t\tstart = 4 * (best_anchor_for_bbox[idx,2] + n_anchratios * best_anchor_for_bbox[idx,3])\n",
        "\t\t\ty_rpn_regr[\n",
        "\t\t\t\tbest_anchor_for_bbox[idx,0], best_anchor_for_bbox[idx,1], start:start+4] = best_dx_for_bbox[idx, :]\n",
        "\n",
        "\ty_rpn_overlap = np.transpose(y_rpn_overlap, (2, 0, 1))\n",
        "\ty_rpn_overlap = np.expand_dims(y_rpn_overlap, axis=0)\n",
        "\n",
        "\ty_is_box_valid = np.transpose(y_is_box_valid, (2, 0, 1))\n",
        "\ty_is_box_valid = np.expand_dims(y_is_box_valid, axis=0)\n",
        "\n",
        "\ty_rpn_regr = np.transpose(y_rpn_regr, (2, 0, 1))\n",
        "\ty_rpn_regr = np.expand_dims(y_rpn_regr, axis=0)\n",
        "\n",
        "\tpos_locs = np.where(np.logical_and(y_rpn_overlap[0, :, :, :] == 1, y_is_box_valid[0, :, :, :] == 1))\n",
        "\tneg_locs = np.where(np.logical_and(y_rpn_overlap[0, :, :, :] == 0, y_is_box_valid[0, :, :, :] == 1))\n",
        "\n",
        "\tnum_pos = len(pos_locs[0])\n",
        "\n",
        "\tnum_regions = 256\n",
        "\n",
        "\tif len(pos_locs[0]) > num_regions/2:\n",
        "\t\tval_locs = random.sample(range(len(pos_locs[0])), len(pos_locs[0]) - num_regions/2)\n",
        "\t\ty_is_box_valid[0, pos_locs[0][val_locs], pos_locs[1][val_locs], pos_locs[2][val_locs]] = 0\n",
        "\t\tnum_pos = num_regions/2\n",
        "\n",
        "\tif len(neg_locs[0]) + num_pos > num_regions:\n",
        "\t\tval_locs = random.sample(range(len(neg_locs[0])), len(neg_locs[0]) - num_pos)\n",
        "\t\ty_is_box_valid[0, neg_locs[0][val_locs], neg_locs[1][val_locs], neg_locs[2][val_locs]] = 0\n",
        "\n",
        "\ty_rpn_cls = np.concatenate([y_is_box_valid, y_rpn_overlap], axis=1)\n",
        "\ty_rpn_regr = np.concatenate([np.repeat(y_rpn_overlap, 4, axis=1), y_rpn_regr], axis=1)\n",
        "\n",
        "\treturn np.copy(y_rpn_cls), np.copy(y_rpn_regr), num_pos\n",
        "\n",
        "def get_new_img_size(width, height, img_min_side=600):\n",
        "\tif width <= height:\n",
        "\t\tf = float(img_min_side) / width\n",
        "\t\tresized_height = int(f * height)\n",
        "\t\tresized_width = img_min_side\n",
        "\telse:\n",
        "\t\tf = float(img_min_side) / height\n",
        "\t\tresized_width = int(f * width)\n",
        "\t\tresized_height = img_min_side\n",
        "\n",
        "\treturn resized_width, resized_height\n",
        "\n",
        "def augment(img_data, config, augment=True):\n",
        "\tassert 'filepath' in img_data\n",
        "\tassert 'bboxes' in img_data\n",
        "\tassert 'width' in img_data\n",
        "\tassert 'height' in img_data\n",
        "\n",
        "\timg_data_aug = copy.deepcopy(img_data)\n",
        "\n",
        "\timg = cv2.imread(img_data_aug['filepath'])\n",
        "\n",
        "\tif augment:\n",
        "\t\trows, cols = img.shape[:2]\n",
        "\n",
        "\t\tif config.use_horizontal_flips and np.random.randint(0, 2) == 0:\n",
        "\t\t\timg = cv2.flip(img, 1)\n",
        "\t\t\tfor bbox in img_data_aug['bboxes']:\n",
        "\t\t\t\tx1 = bbox['x1']\n",
        "\t\t\t\tx2 = bbox['x2']\n",
        "\t\t\t\tbbox['x2'] = cols - x1\n",
        "\t\t\t\tbbox['x1'] = cols - x2\n",
        "\n",
        "\t\tif config.use_vertical_flips and np.random.randint(0, 2) == 0:\n",
        "\t\t\timg = cv2.flip(img, 0)\n",
        "\t\t\tfor bbox in img_data_aug['bboxes']:\n",
        "\t\t\t\ty1 = bbox['y1']\n",
        "\t\t\t\ty2 = bbox['y2']\n",
        "\t\t\t\tbbox['y2'] = rows - y1\n",
        "\t\t\t\tbbox['y1'] = rows - y2\n",
        "\n",
        "\t\tif config.rot_90:\n",
        "\t\t\tangle = np.random.choice([0,90,180,270],1)[0]\n",
        "\t\t\tif angle == 270:\n",
        "\t\t\t\timg = np.transpose(img, (1,0,2))\n",
        "\t\t\t\timg = cv2.flip(img, 0)\n",
        "\t\t\telif angle == 180:\n",
        "\t\t\t\timg = cv2.flip(img, -1)\n",
        "\t\t\telif angle == 90:\n",
        "\t\t\t\timg = np.transpose(img, (1,0,2))\n",
        "\t\t\t\timg = cv2.flip(img, 1)\n",
        "\t\t\telif angle == 0:\n",
        "\t\t\t\tpass\n",
        "\n",
        "\t\t\tfor bbox in img_data_aug['bboxes']:\n",
        "\t\t\t\tx1 = bbox['x1']\n",
        "\t\t\t\tx2 = bbox['x2']\n",
        "\t\t\t\ty1 = bbox['y1']\n",
        "\t\t\t\ty2 = bbox['y2']\n",
        "\t\t\t\tif angle == 270:\n",
        "\t\t\t\t\tbbox['x1'] = y1\n",
        "\t\t\t\t\tbbox['x2'] = y2\n",
        "\t\t\t\t\tbbox['y1'] = cols - x2\n",
        "\t\t\t\t\tbbox['y2'] = cols - x1\n",
        "\t\t\t\telif angle == 180:\n",
        "\t\t\t\t\tbbox['x2'] = cols - x1\n",
        "\t\t\t\t\tbbox['x1'] = cols - x2\n",
        "\t\t\t\t\tbbox['y2'] = rows - y1\n",
        "\t\t\t\t\tbbox['y1'] = rows - y2\n",
        "\t\t\t\telif angle == 90:\n",
        "\t\t\t\t\tbbox['x1'] = rows - y2\n",
        "\t\t\t\t\tbbox['x2'] = rows - y1\n",
        "\t\t\t\t\tbbox['y1'] = x1\n",
        "\t\t\t\t\tbbox['y2'] = x2        \n",
        "\t\t\t\telif angle == 0:\n",
        "\t\t\t\t\tpass\n",
        "\n",
        "\timg_data_aug['width'] = img.shape[1]\n",
        "\timg_data_aug['height'] = img.shape[0]\n",
        "\treturn img_data_aug, img\n",
        "\n",
        "def get_anchor_gt(all_img_data, C, img_length_calc_function, mode='abc'):\n",
        "\n",
        "\twhile True:\n",
        "\n",
        "\t\tfor img_data in all_img_data:\n",
        "\t\t\ttry:\n",
        "\t\t\t\tif mode == 'train':\n",
        "\t\t\t\t\timg_data_aug, x_img = augment(img_data, C, augment=True)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\timg_data_aug, x_img = augment(img_data, C, augment=False)\n",
        "\n",
        "\t\t\t\t(width, height) = (img_data_aug['width'], img_data_aug['height'])\n",
        "\t\t\t\t(rows, cols, _) = x_img.shape\n",
        "\n",
        "\t\t\t\tassert cols == width\n",
        "\t\t\t\tassert rows == height\n",
        "\n",
        "\t\t\t\t(resized_width, resized_height) = get_new_img_size(width, height, C.im_size)\n",
        "\n",
        "\t\t\t\tx_img = cv2.resize(x_img, (resized_width, resized_height), interpolation=cv2.INTER_CUBIC)\n",
        "\t\t\t\tdebug_img = x_img.copy()\n",
        "\n",
        "\t\t\t\ttry:\n",
        "\t\t\t\t\ty_rpn_cls, y_rpn_regr, num_pos = calc_rpn(C, img_data_aug, width, height, resized_width, resized_height, img_length_calc_function)\n",
        "\t\t\t\texcept:\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\tx_img = x_img.astype(np.float32)\n",
        "\t\t\t\tx_img[:, :, 0] -= C.img_channel_mean[0]\n",
        "\t\t\t\tx_img[:, :, 1] -= C.img_channel_mean[1]\n",
        "\t\t\t\tx_img[:, :, 2] -= C.img_channel_mean[2]\n",
        "\t\t\t\tx_img /= C.img_scaling_factor\n",
        "\n",
        "\t\t\t\tx_img = np.transpose(x_img, (2, 0, 1))\n",
        "\t\t\t\tx_img = np.expand_dims(x_img, axis=0)\n",
        "\n",
        "\t\t\t\ty_rpn_regr[:, y_rpn_regr.shape[1]//2:, :, :] *= C.std_scaling\n",
        "\n",
        "\t\t\t\tx_img = np.transpose(x_img, (0, 2, 3, 1))\n",
        "\t\t\t\ty_rpn_cls = np.transpose(y_rpn_cls, (0, 2, 3, 1))\n",
        "\t\t\t\ty_rpn_regr = np.transpose(y_rpn_regr, (0, 2, 3, 1))\n",
        "\n",
        "\t\t\t\tyield np.copy(x_img), [np.copy(y_rpn_cls), np.copy(y_rpn_regr)], img_data_aug, debug_img, num_pos\n",
        "\n",
        "\t\t\texcept Exception as e:\n",
        "\t\t\t\tprint(e)\n",
        "\t\t\t\tcontinue\n",
        "\n",
        "def non_max_suppression_fast(boxes, probs, overlap_thresh=0.9, max_boxes=300):\n",
        "    if len(boxes) == 0:\n",
        "        return []\n",
        "\n",
        "    x1 = boxes[:, 0]\n",
        "    y1 = boxes[:, 1]\n",
        "    x2 = boxes[:, 2]\n",
        "    y2 = boxes[:, 3]\n",
        "\n",
        "    np.testing.assert_array_less(x1, x2)\n",
        "    np.testing.assert_array_less(y1, y2)\n",
        "\n",
        "    if boxes.dtype.kind == \"i\":\n",
        "        boxes = boxes.astype(\"float\")\n",
        "    pick = []\n",
        "    area = (x2 - x1) * (y2 - y1)\n",
        "    idxs = np.argsort(probs)\n",
        "    while len(idxs) > 0:\n",
        "        last = len(idxs) - 1\n",
        "        i = idxs[last]\n",
        "        pick.append(i)\n",
        "        xx1_int = np.maximum(x1[i], x1[idxs[:last]])\n",
        "        yy1_int = np.maximum(y1[i], y1[idxs[:last]])\n",
        "        xx2_int = np.minimum(x2[i], x2[idxs[:last]])\n",
        "        yy2_int = np.minimum(y2[i], y2[idxs[:last]])\n",
        "\n",
        "        ww_int = np.maximum(0, xx2_int - xx1_int)\n",
        "        hh_int = np.maximum(0, yy2_int - yy1_int)\n",
        "\n",
        "        area_int = ww_int * hh_int\n",
        "        area_union = area[i] + area[idxs[:last]] - area_int\n",
        "\n",
        "        overlap = area_int/(area_union + 1e-6)\n",
        "        idxs = np.delete(idxs, np.concatenate(([last],\n",
        "            np.where(overlap > overlap_thresh)[0])))\n",
        "\n",
        "        if len(pick) >= max_boxes:\n",
        "            break\n",
        "\n",
        "    boxes = boxes[pick].astype(\"int\")\n",
        "    probs = probs[pick]\n",
        "    return boxes, probs\n",
        "\n",
        "def apply_regr_np(X, T):\n",
        "    try:\n",
        "        x = X[0, :, :]\n",
        "        y = X[1, :, :]\n",
        "        w = X[2, :, :]\n",
        "        h = X[3, :, :]\n",
        "\n",
        "        tx = T[0, :, :]\n",
        "        ty = T[1, :, :]\n",
        "        tw = T[2, :, :]\n",
        "        th = T[3, :, :]\n",
        "\n",
        "        cx = x + w/2.\n",
        "        cy = y + h/2.\n",
        "        cx1 = tx * w + cx\n",
        "        cy1 = ty * h + cy\n",
        "\n",
        "        w1 = np.exp(tw.astype(np.float64)) * w\n",
        "        h1 = np.exp(th.astype(np.float64)) * h\n",
        "        x1 = cx1 - w1/2.\n",
        "        y1 = cy1 - h1/2.\n",
        "\n",
        "        x1 = np.round(x1)\n",
        "        y1 = np.round(y1)\n",
        "        w1 = np.round(w1)\n",
        "        h1 = np.round(h1)\n",
        "        return np.stack([x1, y1, w1, h1])\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        return X\n",
        "    \n",
        "def apply_regr(x, y, w, h, tx, ty, tw, th):\n",
        "    try:\n",
        "        cx = x + w/2.\n",
        "        cy = y + h/2.\n",
        "        cx1 = tx * w + cx\n",
        "        cy1 = ty * h + cy\n",
        "        w1 = math.exp(tw) * w\n",
        "        h1 = math.exp(th) * h\n",
        "        x1 = cx1 - w1/2.\n",
        "        y1 = cy1 - h1/2.\n",
        "        x1 = int(round(x1))\n",
        "        y1 = int(round(y1))\n",
        "        w1 = int(round(w1))\n",
        "        h1 = int(round(h1))\n",
        "\n",
        "        return x1, y1, w1, h1\n",
        "\n",
        "    except ValueError:\n",
        "        return x, y, w, h\n",
        "    except OverflowError:\n",
        "        return x, y, w, h\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        return x, y, w, h\n",
        "\n",
        "def calc_iou(R, img_data, C, class_mapping):\n",
        "    bboxes = img_data['bboxes']\n",
        "    (width, height) = (img_data['width'], img_data['height'])\n",
        "    (resized_width, resized_height) = get_new_img_size(width, height, C.im_size)\n",
        "\n",
        "    gta = np.zeros((len(bboxes), 4))\n",
        "\n",
        "    for bbox_num, bbox in enumerate(bboxes):\n",
        "        gta[bbox_num, 0] = int(round(bbox['x1'] * (resized_width / float(width))/C.rpn_stride))\n",
        "        gta[bbox_num, 1] = int(round(bbox['x2'] * (resized_width / float(width))/C.rpn_stride))\n",
        "        gta[bbox_num, 2] = int(round(bbox['y1'] * (resized_height / float(height))/C.rpn_stride))\n",
        "        gta[bbox_num, 3] = int(round(bbox['y2'] * (resized_height / float(height))/C.rpn_stride))\n",
        "\n",
        "    x_roi = []\n",
        "    y_class_num = []\n",
        "    y_class_regr_coords = []\n",
        "    y_class_regr_label = []\n",
        "    IoUs = []\n",
        "\n",
        "    for ix in range(R.shape[0]):\n",
        "        (x1, y1, x2, y2) = R[ix, :]\n",
        "        x1 = int(round(x1))\n",
        "        y1 = int(round(y1))\n",
        "        x2 = int(round(x2))\n",
        "        y2 = int(round(y2))\n",
        "\n",
        "        best_iou = 0.0\n",
        "        best_bbox = -1\n",
        "    \n",
        "        for bbox_num in range(len(bboxes)):\n",
        "            curr_iou = iou([gta[bbox_num, 0], gta[bbox_num, 2], gta[bbox_num, 1], gta[bbox_num, 3]], [x1, y1, x2, y2])\n",
        "\n",
        "            if curr_iou > best_iou:\n",
        "                best_iou = curr_iou\n",
        "                best_bbox = bbox_num\n",
        "\n",
        "        if best_iou < C.classifier_min_overlap:\n",
        "                continue\n",
        "        else:\n",
        "            w = x2 - x1\n",
        "            h = y2 - y1\n",
        "            x_roi.append([x1, y1, w, h])\n",
        "            IoUs.append(best_iou)\n",
        "\n",
        "            if C.classifier_min_overlap <= best_iou < C.classifier_max_overlap:\n",
        "                cls_name = 'bg'\n",
        "            elif C.classifier_max_overlap <= best_iou:\n",
        "                cls_name = bboxes[best_bbox]['class']\n",
        "                cxg = (gta[best_bbox, 0] + gta[best_bbox, 1]) / 2.0\n",
        "                cyg = (gta[best_bbox, 2] + gta[best_bbox, 3]) / 2.0\n",
        "\n",
        "                cx = x1 + w / 2.0\n",
        "                cy = y1 + h / 2.0\n",
        "\n",
        "                tx = (cxg - cx) / float(w)\n",
        "                ty = (cyg - cy) / float(h)\n",
        "                tw = np.log((gta[best_bbox, 1] - gta[best_bbox, 0]) / float(w))\n",
        "                th = np.log((gta[best_bbox, 3] - gta[best_bbox, 2]) / float(h))\n",
        "            else:\n",
        "                print('roi = {}'.format(best_iou))\n",
        "                raise RuntimeError\n",
        "\n",
        "        class_num = class_mapping[cls_name]\n",
        "        class_label = len(class_mapping) * [0]\n",
        "        class_label[class_num] = 1\n",
        "        y_class_num.append(copy.deepcopy(class_label))\n",
        "        coords = [0] * 4 * (len(class_mapping) - 1)\n",
        "        labels = [0] * 4 * (len(class_mapping) - 1)\n",
        "        if cls_name != 'bg':\n",
        "            label_pos = 4 * class_num\n",
        "            sx, sy, sw, sh = C.classifier_regr_std\n",
        "            coords[label_pos:4+label_pos] = [sx*tx, sy*ty, sw*tw, sh*th]\n",
        "            labels[label_pos:4+label_pos] = [1, 1, 1, 1]\n",
        "            y_class_regr_coords.append(copy.deepcopy(coords))\n",
        "            y_class_regr_label.append(copy.deepcopy(labels))\n",
        "        else:\n",
        "            y_class_regr_coords.append(copy.deepcopy(coords))\n",
        "            y_class_regr_label.append(copy.deepcopy(labels))\n",
        "\n",
        "    if len(x_roi) == 0:\n",
        "        return None, None, None, None\n",
        "\n",
        "    X = np.array(x_roi)\n",
        "    Y1 = np.array(y_class_num)\n",
        "    Y2 = np.concatenate([np.array(y_class_regr_label),np.array(y_class_regr_coords)],axis=1)\n",
        "\n",
        "    return np.expand_dims(X, axis=0), np.expand_dims(Y1, axis=0), np.expand_dims(Y2, axis=0), IoUs\n",
        "\n",
        "def rpn_to_roi(rpn_layer, regr_layer, C, dim_ordering, use_regr=True, max_boxes=300,overlap_thresh=0.9):\n",
        "\t\n",
        "\tregr_layer = regr_layer / C.std_scaling\n",
        "\n",
        "\tanchor_sizes = C.anchor_box_scales  \n",
        "\tanchor_ratios = C.anchor_box_ratios  \n",
        "\n",
        "\tassert rpn_layer.shape[0] == 1\n",
        "\n",
        "\t(rows, cols) = rpn_layer.shape[1:3]\n",
        "\n",
        "\tcurr_layer = 0\n",
        "\n",
        "\tA = np.zeros((4, rpn_layer.shape[1], rpn_layer.shape[2], rpn_layer.shape[3]))\n",
        "\n",
        "\tfor anchor_size in anchor_sizes:\n",
        "\t\tfor anchor_ratio in anchor_ratios:\n",
        "\t\t\tanchor_x = (anchor_size * anchor_ratio[0])/C.rpn_stride\n",
        "\t\t\tanchor_y = (anchor_size * anchor_ratio[1])/C.rpn_stride\n",
        "\n",
        "\t\t\tregr = regr_layer[0, :, :, 4 * curr_layer:4 * curr_layer + 4] \n",
        "\t\t\tregr = np.transpose(regr, (2, 0, 1)) \n",
        "\t\t\t\n",
        "\t\t\tX, Y = np.meshgrid(np.arange(cols),np. arange(rows))\n",
        "\t\t\tA[0, :, :, curr_layer] = X - anchor_x/2 \n",
        "\t\t\tA[1, :, :, curr_layer] = Y - anchor_y/2 \n",
        "\t\t\tA[2, :, :, curr_layer] = anchor_x       \n",
        "\t\t\tA[3, :, :, curr_layer] = anchor_y      \n",
        "\t\t\tif use_regr:\n",
        "\t\t\t\tA[:, :, :, curr_layer] = apply_regr_np(A[:, :, :, curr_layer], regr)\n",
        "\t\t\t\n",
        "\t\t\tA[2, :, :, curr_layer] = np.maximum(1, A[2, :, :, curr_layer])\n",
        "\t\t\tA[3, :, :, curr_layer] = np.maximum(1, A[3, :, :, curr_layer])\n",
        "\t\t\t\n",
        "\t\t\tA[2, :, :, curr_layer] += A[0, :, :, curr_layer]\n",
        "\t\t\tA[3, :, :, curr_layer] += A[1, :, :, curr_layer]\n",
        "\n",
        "\t\t\tA[0, :, :, curr_layer] = np.maximum(0, A[0, :, :, curr_layer])\n",
        "\t\t\tA[1, :, :, curr_layer] = np.maximum(0, A[1, :, :, curr_layer])\n",
        "\t\t\tA[2, :, :, curr_layer] = np.minimum(cols-1, A[2, :, :, curr_layer])\n",
        "\t\t\tA[3, :, :, curr_layer] = np.minimum(rows-1, A[3, :, :, curr_layer])\n",
        "\n",
        "\t\t\tcurr_layer += 1\n",
        "\n",
        "\tall_boxes = np.reshape(A.transpose((0, 3, 1, 2)), (4, -1)).transpose((1, 0))  \n",
        "\tall_probs = rpn_layer.transpose((0, 3, 1, 2)).reshape((-1))                  \n",
        "\n",
        "\tx1 = all_boxes[:, 0]\n",
        "\ty1 = all_boxes[:, 1]\n",
        "\tx2 = all_boxes[:, 2]\n",
        "\ty2 = all_boxes[:, 3]\n",
        "\n",
        "\tidxs = np.where((x1 - x2 >= 0) | (y1 - y2 >= 0))\n",
        "\n",
        "\tall_boxes = np.delete(all_boxes, idxs, 0)\n",
        "\tall_probs = np.delete(all_probs, idxs, 0)\n",
        "\n",
        "\tresult = non_max_suppression_fast(all_boxes, all_probs, overlap_thresh=overlap_thresh, max_boxes=max_boxes)[0]\n",
        "\n",
        "\treturn result\n",
        "\n",
        "lambda_rpn_regr = 1.0\n",
        "lambda_rpn_class = 1.0\n",
        "\n",
        "lambda_cls_regr = 1.0\n",
        "lambda_cls_class = 1.0\n",
        "\n",
        "epsilon = 1e-4\n",
        "\n",
        "def rpn_loss_regr(num_anchors):\n",
        "   \n",
        "    def rpn_loss_regr_fixed_num(y_true, y_pred):\n",
        "\n",
        "        x = y_true[:, :, :, 4 * num_anchors:] - y_pred\n",
        "        x_abs = K.abs(x)\n",
        "        x_bool = K.cast(K.less_equal(x_abs, 1.0), tf.float32)\n",
        "\n",
        "        return lambda_rpn_regr * K.sum(\n",
        "            y_true[:, :, :, :4 * num_anchors] * (x_bool * (0.5 * x * x) + (1 - x_bool) * (x_abs - 0.5))) / K.sum(epsilon + y_true[:, :, :, :4 * num_anchors])\n",
        "\n",
        "    return rpn_loss_regr_fixed_num\n",
        "\n",
        "\n",
        "def rpn_loss_cls(num_anchors):\n",
        "   \n",
        "    def rpn_loss_cls_fixed_num(y_true, y_pred):\n",
        "\n",
        "            return lambda_rpn_class * K.sum(y_true[:, :, :, :num_anchors] * K.binary_crossentropy(y_pred[:, :, :, :], y_true[:, :, :, num_anchors:])) / K.sum(epsilon + y_true[:, :, :, :num_anchors])\n",
        "\n",
        "    return rpn_loss_cls_fixed_num\n",
        "\n",
        "\n",
        "def class_loss_regr(num_classes):\n",
        "    \n",
        "    def class_loss_regr_fixed_num(y_true, y_pred):\n",
        "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
        "        x_abs = K.abs(x)\n",
        "        x_bool = K.cast(K.less_equal(x_abs, 1.0), 'float32')\n",
        "        return lambda_cls_regr * K.sum(y_true[:, :, :4*num_classes] * (x_bool * (0.5 * x * x) + (1 - x_bool) * (x_abs - 0.5))) / K.sum(epsilon + y_true[:, :, :4*num_classes])\n",
        "    return class_loss_regr_fixed_num\n",
        "\n",
        "\n",
        "def class_loss_cls(y_true, y_pred):\n",
        "    return lambda_cls_class * K.mean(categorical_crossentropy(y_true[0, :, :], y_pred[0, :, :]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iizV53KpGh-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RoiPoolingConv(Layer):\n",
        "    \n",
        "    def __init__(self, pool_size, num_rois, **kwargs):\n",
        "        self.pool_size = pool_size\n",
        "        self.num_rois = num_rois\n",
        "\n",
        "        super(RoiPoolingConv, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.nb_channels = input_shape[0][3]   \n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return None, self.num_rois, self.pool_size, self.pool_size, self.nb_channels\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "\n",
        "        assert(len(x) == 2)\n",
        "        img = x[0]\n",
        "        rois = x[1]\n",
        "        input_shape = K.shape(img)\n",
        "        outputs = []\n",
        "\n",
        "        for roi_idx in range(self.num_rois):\n",
        "\n",
        "            x = rois[0, roi_idx, 0]\n",
        "            y = rois[0, roi_idx, 1]\n",
        "            w = rois[0, roi_idx, 2]\n",
        "            h = rois[0, roi_idx, 3]\n",
        "\n",
        "            x = K.cast(x, 'int32')\n",
        "            y = K.cast(y, 'int32')\n",
        "            w = K.cast(w, 'int32')\n",
        "            h = K.cast(h, 'int32')\n",
        "\n",
        "            rs = tf.image.resize(img[:, y:y+h, x:x+w, :], (self.pool_size, self.pool_size))\n",
        "            outputs.append(rs)\n",
        "                \n",
        "\n",
        "        final_output = K.concatenate(outputs, axis=0)\n",
        "        final_output = K.reshape(final_output, (1, self.num_rois, self.pool_size, self.pool_size, self.nb_channels))\n",
        "        final_output = K.permute_dimensions(final_output, (0, 1, 2, 3, 4))\n",
        "\n",
        "        return final_output\n",
        "    \n",
        "    \n",
        "    def get_config(self):\n",
        "        config = {'pool_size': self.pool_size,\n",
        "                  'num_rois': self.num_rois}\n",
        "        base_config = super(RoiPoolingConv, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "class FixedBatchNormalization(Layer):\n",
        "\n",
        "\tdef __init__(self, epsilon=1e-3, axis=-1,\n",
        "\t\t\t\t weights=None, beta_init='zero', gamma_init='one',\n",
        "\t\t\t\t gamma_regularizer=None, beta_regularizer=None, **kwargs):\n",
        "\n",
        "\t\tself.supports_masking = True\n",
        "\t\tself.beta_init = initializers.get(beta_init)\n",
        "\t\tself.gamma_init = initializers.get(gamma_init)\n",
        "\t\tself.epsilon = epsilon\n",
        "\t\tself.axis = axis\n",
        "\t\tself.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
        "\t\tself.beta_regularizer = regularizers.get(beta_regularizer)\n",
        "\t\tself.initial_weights = weights\n",
        "\t\tsuper(FixedBatchNormalization, self).__init__(**kwargs)\n",
        "\n",
        "\tdef build(self, input_shape):\n",
        "\t\tself.input_spec = [InputSpec(shape=input_shape)]\n",
        "\t\tshape = (input_shape[self.axis],)\n",
        "\n",
        "\t\tself.gamma = self.add_weight(shape = shape,\n",
        "\t\t\t\t\t\t\t\t\t initializer=self.gamma_init,\n",
        "\t\t\t\t\t\t\t\t\t regularizer=self.gamma_regularizer,\n",
        "\t\t\t\t\t\t\t\t\t name='{}_gamma'.format(self.name),\n",
        "\t\t\t\t\t\t\t\t\t trainable=False)\n",
        "\t\tself.beta = self.add_weight(shape = shape,\n",
        "\t\t\t\t\t\t\t\t\tinitializer=self.beta_init,\n",
        "\t\t\t\t\t\t\t\t\tregularizer=self.beta_regularizer,\n",
        "\t\t\t\t\t\t\t\t\tname='{}_beta'.format(self.name),\n",
        "\t\t\t\t\t\t\t\t\ttrainable=False)\n",
        "\t\tself.running_mean = self.add_weight(shape = shape, initializer='zero',\n",
        "\t\t\t\t\t\t\t\t\t\t\tname='{}_running_mean'.format(self.name),\n",
        "\t\t\t\t\t\t\t\t\t\t\ttrainable=False)\n",
        "\t\tself.running_std = self.add_weight(shape = shape, initializer='one',\n",
        "\t\t\t\t\t\t\t\t\t\t   name='{}_running_std'.format(self.name),\n",
        "\t\t\t\t\t\t\t\t\t\t   trainable=False)\n",
        "\n",
        "\t\tif self.initial_weights is not None:\n",
        "\t\t\tself.set_weights(self.initial_weights)\n",
        "\t\t\tdel self.initial_weights\n",
        "\n",
        "\t\tself.built = True\n",
        "\n",
        "\tdef call(self, x, mask=None):\n",
        "\n",
        "\t\tassert self.built, 'Layer must be built before being called'\n",
        "\t\tinput_shape = K.int_shape(x)\n",
        "\n",
        "\t\treduction_axes = list(range(len(input_shape)))\n",
        "\t\tdel reduction_axes[self.axis]\n",
        "\t\tbroadcast_shape = [1] * len(input_shape)\n",
        "\t\tbroadcast_shape[self.axis] = input_shape[self.axis]\n",
        "\n",
        "\t\tif sorted(reduction_axes) == range(K.ndim(x))[:-1]:\n",
        "\t\t\tx_normed = K.batch_normalization(\n",
        "\t\t\t\tx, self.running_mean, self.running_std,\n",
        "\t\t\t\tself.beta, self.gamma,\n",
        "\t\t\t\tepsilon=self.epsilon)\n",
        "\t\telse:\n",
        "\t\t\tbroadcast_running_mean = K.reshape(self.running_mean, broadcast_shape)\n",
        "\t\t\tbroadcast_running_std = K.reshape(self.running_std, broadcast_shape)\n",
        "\t\t\tbroadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
        "\t\t\tbroadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
        "\t\t\tx_normed = K.batch_normalization(\n",
        "\t\t\t\tx, broadcast_running_mean, broadcast_running_std,\n",
        "\t\t\t\tbroadcast_beta, broadcast_gamma,\n",
        "\t\t\t\tepsilon=self.epsilon)\n",
        "\n",
        "\t\treturn x_normed\n",
        "\n",
        "\tdef get_config(self):\n",
        "\t\tconfig = {'epsilon': self.epsilon,\n",
        "\t\t\t\t  'axis': self.axis,\n",
        "\t\t\t\t  'gamma_regularizer': self.gamma_regularizer.get_config() if self.gamma_regularizer else None,\n",
        "\t\t\t\t  'beta_regularizer': self.beta_regularizer.get_config() if self.beta_regularizer else None}\n",
        "\t\tbase_config = super(FixedBatchNormalization, self).get_config()\n",
        "\t\treturn dict(list(base_config.items()) + list(config.items()))\n",
        "  \n",
        "def get_img_output_length(width, height):\n",
        "    def get_output_length(input_length):\n",
        "        input_length += 6\n",
        "        filter_sizes = [7, 3, 1, 1]\n",
        "        stride = 2\n",
        "        for filter_size in filter_sizes:\n",
        "            input_length = (input_length - filter_size + stride) // stride\n",
        "        return input_length\n",
        "\n",
        "    return get_output_length(width), get_output_length(height)\n",
        "\n",
        "def identity_block(input_tensor, kernel_size, filters, stage, block, trainable=True):\n",
        "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
        "    bn_axis = 3\n",
        "\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = Convolution2D(nb_filter1, (1, 1), name=conv_name_base + '2a', trainable=trainable)(input_tensor)\n",
        "    x = FixedBatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(nb_filter2, (kernel_size, kernel_size), padding='same', name=conv_name_base + '2b',\n",
        "                      trainable=trainable)(x)\n",
        "    x = FixedBatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(nb_filter3, (1, 1), name=conv_name_base + '2c', trainable=trainable)(x)\n",
        "    x = FixedBatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    x = Add()([x, input_tensor])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def identity_block_td(input_tensor, kernel_size, filters, stage, block, trainable=True):\n",
        "\n",
        "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
        "    bn_axis = 3\n",
        "\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = TimeDistributed(Convolution2D(nb_filter1, (1, 1), trainable=trainable, kernel_initializer='normal'),\n",
        "                        name=conv_name_base + '2a')(input_tensor)\n",
        "    x = TimeDistributed(FixedBatchNormalization(axis=bn_axis), name=bn_name_base + '2a')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = TimeDistributed(\n",
        "        Convolution2D(nb_filter2, (kernel_size, kernel_size), trainable=trainable, kernel_initializer='normal',\n",
        "                      padding='same'), name=conv_name_base + '2b')(x)\n",
        "    x = TimeDistributed(FixedBatchNormalization(axis=bn_axis), name=bn_name_base + '2b')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = TimeDistributed(Convolution2D(nb_filter3, (1, 1), trainable=trainable, kernel_initializer='normal'),\n",
        "                        name=conv_name_base + '2c')(x)\n",
        "    x = TimeDistributed(FixedBatchNormalization(axis=bn_axis), name=bn_name_base + '2c')(x)\n",
        "\n",
        "    x = Add()([x, input_tensor])\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2), trainable=True):\n",
        "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
        "    bn_axis = 3\n",
        "\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = Convolution2D(nb_filter1, (1, 1), strides=strides, name=conv_name_base + '2a', trainable=trainable)(\n",
        "        input_tensor)\n",
        "    x = FixedBatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(nb_filter2, (kernel_size, kernel_size), padding='same', name=conv_name_base + '2b',\n",
        "                      trainable=trainable)(x)\n",
        "    x = FixedBatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(nb_filter3, (1, 1), name=conv_name_base + '2c', trainable=trainable)(x)\n",
        "    x = FixedBatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    shortcut = Convolution2D(nb_filter3, (1, 1), strides=strides, name=conv_name_base + '1', trainable=trainable)(\n",
        "        input_tensor)\n",
        "    shortcut = FixedBatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
        "\n",
        "    x = Add()([x, shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def conv_block_td(input_tensor, kernel_size, filters, stage, block, input_shape, strides=(2, 2), trainable=True):\n",
        "\n",
        "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
        "    bn_axis = 3\n",
        "\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = TimeDistributed(\n",
        "        Convolution2D(nb_filter1, (1, 1), strides=strides, trainable=trainable, kernel_initializer='normal'),\n",
        "        input_shape=input_shape, name=conv_name_base + '2a')(input_tensor)\n",
        "    x = TimeDistributed(FixedBatchNormalization(axis=bn_axis), name=bn_name_base + '2a')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = TimeDistributed(Convolution2D(nb_filter2, (kernel_size, kernel_size), padding='same', trainable=trainable,\n",
        "                                      kernel_initializer='normal'), name=conv_name_base + '2b')(x)\n",
        "    x = TimeDistributed(FixedBatchNormalization(axis=bn_axis), name=bn_name_base + '2b')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = TimeDistributed(Convolution2D(nb_filter3, (1, 1), kernel_initializer='normal'), name=conv_name_base + '2c',\n",
        "                        trainable=trainable)(x)\n",
        "    x = TimeDistributed(FixedBatchNormalization(axis=bn_axis), name=bn_name_base + '2c')(x)\n",
        "\n",
        "    shortcut = TimeDistributed(\n",
        "        Convolution2D(nb_filter3, (1, 1), strides=strides, trainable=trainable, kernel_initializer='normal'),\n",
        "        name=conv_name_base + '1')(input_tensor)\n",
        "    shortcut = TimeDistributed(FixedBatchNormalization(axis=bn_axis), name=bn_name_base + '1')(shortcut)\n",
        "\n",
        "    x = Add()([x, shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def nn_base(input_tensor=None, trainable=False):\n",
        "    input_shape = (3, None, None)\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = Input(shape=input_shape)\n",
        "    else:\n",
        "        if not K.is_keras_tensor(input_tensor):\n",
        "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "\n",
        "    bn_axis = 3\n",
        "\n",
        "    x = ZeroPadding2D((3, 3))(img_input)\n",
        "\n",
        "    x = Convolution2D(64, (7, 7), strides=(2, 2), name='conv1', trainable=trainable)(x)\n",
        "    x = FixedBatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1), trainable=trainable)\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b', trainable=trainable)\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c', trainable=trainable)\n",
        "\n",
        "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a', trainable=trainable)\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b', trainable=trainable)\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c', trainable=trainable)\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d', trainable=trainable)\n",
        "\n",
        "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a', trainable=trainable)\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b', trainable=trainable)\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c', trainable=trainable)\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d', trainable=trainable)\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e', trainable=trainable)\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f', trainable=trainable)\n",
        "\n",
        "    return x\n",
        "\n",
        "def rpn_layer(base_layers, num_anchors):\n",
        "\t\n",
        "\tx = Conv2D(512, (3, 3), padding='same', activation='relu', kernel_initializer='normal', name='rpn_conv1')(base_layers)\n",
        "\n",
        "\tx_class = Conv2D(num_anchors, (1, 1), activation='sigmoid', kernel_initializer='uniform', name='rpn_out_class')(x)\n",
        "\tx_regr = Conv2D(num_anchors * 4, (1, 1), activation='linear', kernel_initializer='zero', name='rpn_out_regress')(x)\n",
        "\n",
        "\treturn [x_class, x_regr, base_layers]\n",
        "\n",
        "def classifier_union(x, input_shape, trainable=False):\n",
        "    x = conv_block_td(x, 3, [512, 512, 2048], stage=5, block='a', input_shape=input_shape, strides=(2, 2),\n",
        "                          trainable=trainable)\n",
        "\n",
        "    x = identity_block_td(x, 3, [512, 512, 2048], stage=5, block='b', trainable=trainable)\n",
        "    x = identity_block_td(x, 3, [512, 512, 2048], stage=5, block='c', trainable=trainable)\n",
        "    x = TimeDistributed(AveragePooling2D((7, 7)), name='avg_pool')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def classifier_layer(base_layers, input_rois, num_rois, nb_classes=7, trainable=False):\n",
        "    pooling_regions = 14\n",
        "    input_shape = (num_rois, 14, 14, 1024)\n",
        "\n",
        "    out_roi_pool = RoiPoolingConv(pooling_regions, num_rois)([base_layers, input_rois])\n",
        "    out = classifier_union(out_roi_pool, input_shape=input_shape, trainable=True)\n",
        "\n",
        "    out = TimeDistributed(Flatten())(out)\n",
        "\n",
        "    out_class = TimeDistributed(Dense(nb_classes, activation='softmax', kernel_initializer='zero'),\n",
        "                                name='dense_class_{}'.format(nb_classes))(out)\n",
        "    out_regr = TimeDistributed(Dense(4 * (nb_classes - 1), activation='linear', kernel_initializer='zero'),\n",
        "                               name='dense_regress_{}'.format(nb_classes))(out)\n",
        "    return [out_class, out_regr]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKmcFJDeLzEH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "e90c57c6-c2b4-4d5c-8e72-c571c2388904"
      },
      "source": [
        "base_path = '/content/drive/My Drive/Colab Notebooks/'\n",
        "\n",
        "train_path =  '/content/drive/My Drive/Colab Notebooks/imgInfo.txt' \n",
        "\n",
        "num_rois = 4\n",
        "\n",
        "\n",
        "horizontal_flips = True \n",
        "vertical_flips = True   \n",
        "rot_90 = True          \n",
        "\n",
        "output_weight_path = os.path.join(base_path, 'model/model_frcnn_resnet50.hdf5')\n",
        "\n",
        "record_path = os.path.join(base_path, 'model/record_resnet.csv') \n",
        "\n",
        "base_weight_path = os.path.join(base_path, 'model/resnet50_weights_tf_dim_ordering_tf_kernels.h5')\n",
        "\n",
        "config_output_filename = os.path.join(base_path, 'model_resnet_config.pickle')\n",
        "\n",
        "C = Config()\n",
        "\n",
        "C.use_horizontal_flips = horizontal_flips\n",
        "C.use_vertical_flips = vertical_flips\n",
        "C.rot_90 = rot_90\n",
        "\n",
        "C.record_path = record_path\n",
        "C.model_path = output_weight_path\n",
        "C.num_rois = num_rois\n",
        "\n",
        "C.base_net_weights = base_weight_path\n",
        "\n",
        "train_imgs, classes_count, class_mapping = get_data()\n",
        "\n",
        "if 'bg' not in classes_count:\n",
        "\tclasses_count['bg'] = 0\n",
        "\tclass_mapping['bg'] = len(class_mapping)\n",
        "\n",
        "C.class_mapping = class_mapping\n",
        "\n",
        "print('Training images per class:')\n",
        "pprint.pprint(classes_count)\n",
        "print('Num classes (including bg) = {}'.format(len(classes_count)))\n",
        "print(class_mapping)\n",
        "\n",
        "with open(config_output_filename, 'wb') as config_f:\n",
        "\tpickle.dump(C,config_f)\n",
        "\tprint('Config has been written to {}, and can be loaded when testing to ensure correct results'.format(config_output_filename))\n",
        "\n",
        "random.seed(1)\n",
        "random.shuffle(train_imgs)\n",
        "\n",
        "data_gen_train = get_anchor_gt(train_imgs, C, get_img_output_length, mode='train')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training images per class:\n",
            "{'Car': 1992,\n",
            " 'Cat': 812,\n",
            " 'Human face': 1863,\n",
            " 'Laptop': 1099,\n",
            " 'Mobile phone': 1062,\n",
            " 'Person': 2918,\n",
            " 'bg': 0}\n",
            "Num classes (including bg) = 7\n",
            "{'Person': 0, 'Car': 1, 'Human face': 2, 'Mobile phone': 3, 'Cat': 4, 'Laptop': 5, 'bg': 6}\n",
            "Config has been written to /content/drive/My Drive/Colab Notebooks/model_resnet_config.pickle, and can be loaded when testing to ensure correct results\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-22rdklcMLCU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7e40c6f9-c562-4e0a-f01c-6661fffc4ffa"
      },
      "source": [
        "input_shape_img = (None, None, 3)\n",
        "\n",
        "img_input = Input(shape=input_shape_img)\n",
        "roi_input = Input(shape=(None, 4))\n",
        "\n",
        "\n",
        "shared_layers = nn_base(img_input, trainable=True)\n",
        "\n",
        "num_anchors = len(C.anchor_box_scales) * len(C.anchor_box_ratios) \n",
        "rpn = rpn_layer(shared_layers, num_anchors)\n",
        "\n",
        "classifier = classifier_layer(shared_layers, roi_input, C.num_rois, nb_classes=len(classes_count), trainable=True)\n",
        "\n",
        "model_rpn = Model(img_input, rpn[:2])\n",
        "model_classifier = Model([img_input, roi_input], classifier)\n",
        "\n",
        "\n",
        "model_all = Model([img_input, roi_input], rpn[:2] + classifier)\n",
        "\n",
        "if not os.path.isfile(C.model_path):\n",
        "    try:\n",
        "        print('This is the first time of your training')\n",
        "        print('loading weights from {}'.format(C.base_net_weights))\n",
        "        model_rpn.load_weights(C.base_net_weights, by_name=True)\n",
        "        model_classifier.load_weights(C.base_net_weights, by_name=True)\n",
        "        print('load weights success')\n",
        "    except:\n",
        "        print('Could not load pretrained model weights. Weights can be found in the keras application folder \\\n",
        "            https://github.com/fchollet/keras/tree/master/keras/applications')\n",
        "    \n",
        "    record_df = pd.DataFrame(columns=['mean_overlapping_bboxes', 'class_acc', 'loss_rpn_cls', 'loss_rpn_regr', 'loss_class_cls', 'loss_class_regr', 'curr_loss', 'elapsed_time', 'mAP'])\n",
        "else:\n",
        "    \n",
        "    print('Continue training based on previous trained model')\n",
        "    print('Loading weights from {}'.format(C.model_path))\n",
        "    model_rpn.load_weights(C.model_path, by_name=True)\n",
        "    model_classifier.load_weights(C.model_path, by_name=True)\n",
        "    \n",
        "    record_df = pd.read_csv(record_path)\n",
        "\n",
        "    r_mean_overlapping_bboxes = record_df['mean_overlapping_bboxes']\n",
        "    r_class_acc = record_df['class_acc']\n",
        "    r_loss_rpn_cls = record_df['loss_rpn_cls']\n",
        "    r_loss_rpn_regr = record_df['loss_rpn_regr']\n",
        "    r_loss_class_cls = record_df['loss_class_cls']\n",
        "    r_loss_class_regr = record_df['loss_class_regr']\n",
        "    r_curr_loss = record_df['curr_loss']\n",
        "    r_elapsed_time = record_df['elapsed_time']\n",
        "    r_mAP = record_df['mAP']\n",
        "\n",
        "    print('Already train %dK batches'% (len(record_df)))\n",
        "\n",
        "optimizer = Adam(lr=1e-5)\n",
        "optimizer_classifier = Adam(lr=1e-5)\n",
        "model_rpn.compile(optimizer=optimizer, loss=[rpn_loss_cls(num_anchors), rpn_loss_regr(num_anchors)])\n",
        "model_classifier.compile(optimizer=optimizer_classifier, loss=[class_loss_cls, class_loss_regr(len(classes_count)-1)], metrics={'dense_class_{}'.format(len(classes_count)): 'accuracy'})\n",
        "model_all.compile(optimizer='sgd', loss='mae')\n",
        "\n",
        "total_epochs = len(record_df)\n",
        "r_epochs = len(record_df)\n",
        "\n",
        "epoch_length = 1000\n",
        "num_epochs = 30\n",
        "iter_num = 0\n",
        "\n",
        "total_epochs += num_epochs\n",
        "\n",
        "losses = np.zeros((epoch_length, 5))\n",
        "rpn_accuracy_rpn_monitor = []\n",
        "rpn_accuracy_for_epoch = []\n",
        "\n",
        "if len(record_df)==0:\n",
        "    best_loss = np.Inf\n",
        "else:\n",
        "    best_loss = np.min(r_curr_loss)\n",
        "\n",
        "start_time = time.time()\n",
        "for epoch_num in range(num_epochs):\n",
        "\n",
        "    progbar = generic_utils.Progbar(epoch_length)\n",
        "    print('Epoch {}/{}'.format(r_epochs + 1, total_epochs))\n",
        "    \n",
        "    r_epochs += 1\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "\n",
        "            if len(rpn_accuracy_rpn_monitor) == epoch_length and C.verbose:\n",
        "                mean_overlapping_bboxes = float(sum(rpn_accuracy_rpn_monitor))/len(rpn_accuracy_rpn_monitor)\n",
        "                rpn_accuracy_rpn_monitor = []\n",
        "                 \n",
        "                if mean_overlapping_bboxes == 0:\n",
        "                    print('RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.')\n",
        "\n",
        "            \n",
        "            X, Y, img_data, debug_img, debug_num_pos = next(data_gen_train)\n",
        "            loss_rpn = model_rpn.train_on_batch(X, Y)\n",
        "            P_rpn = model_rpn.predict_on_batch(X)\n",
        "            R = rpn_to_roi(P_rpn[0], P_rpn[1], C, None, use_regr=True, overlap_thresh=0.7, max_boxes=300)\n",
        "            \n",
        "            X2, Y1, Y2, IouS = calc_iou(R, img_data, C, class_mapping)\n",
        "\n",
        "            if X2 is None:\n",
        "                rpn_accuracy_rpn_monitor.append(0)\n",
        "                rpn_accuracy_for_epoch.append(0)\n",
        "                continue\n",
        "            \n",
        "            neg_samples = np.where(Y1[0, :, -1] == 1)\n",
        "            pos_samples = np.where(Y1[0, :, -1] == 0)\n",
        "\n",
        "            if len(neg_samples) > 0:\n",
        "                neg_samples = neg_samples[0]\n",
        "            else:\n",
        "                neg_samples = []\n",
        "\n",
        "            if len(pos_samples) > 0:\n",
        "                pos_samples = pos_samples[0]\n",
        "            else:\n",
        "                pos_samples = []\n",
        "\n",
        "            rpn_accuracy_rpn_monitor.append(len(pos_samples))\n",
        "            rpn_accuracy_for_epoch.append((len(pos_samples)))\n",
        "\n",
        "            if C.num_rois > 1:\n",
        "                if len(pos_samples) < C.num_rois//2:\n",
        "                    selected_pos_samples = pos_samples.tolist()\n",
        "                else:\n",
        "                    selected_pos_samples = np.random.choice(pos_samples, C.num_rois//2, replace=False).tolist()\n",
        "                \n",
        "                try:\n",
        "                    selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=False).tolist()\n",
        "                except:\n",
        "                    selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=True).tolist()\n",
        "                \n",
        "                sel_samples = selected_pos_samples + selected_neg_samples\n",
        "            else:\n",
        "                selected_pos_samples = pos_samples.tolist()\n",
        "                selected_neg_samples = neg_samples.tolist()\n",
        "                if np.random.randint(0, 2):\n",
        "                    sel_samples = random.choice(neg_samples)\n",
        "                else:\n",
        "                    sel_samples = random.choice(pos_samples)\n",
        "\n",
        "            loss_class = model_classifier.train_on_batch([X, X2[:, sel_samples, :]], [Y1[:, sel_samples, :], Y2[:, sel_samples, :]])\n",
        "\n",
        "            losses[iter_num, 0] = loss_rpn[1]\n",
        "            losses[iter_num, 1] = loss_rpn[2]\n",
        "\n",
        "            losses[iter_num, 2] = loss_class[1]\n",
        "            losses[iter_num, 3] = loss_class[2]\n",
        "            losses[iter_num, 4] = loss_class[3]\n",
        "\n",
        "            iter_num += 1\n",
        "\n",
        "            progbar.update(iter_num, [('rpn_cls', np.mean(losses[:iter_num, 0])), ('rpn_regr', np.mean(losses[:iter_num, 1])),\n",
        "                                      ('final_cls', np.mean(losses[:iter_num, 2])), ('final_regr', np.mean(losses[:iter_num, 3]))])\n",
        "\n",
        "            if iter_num == epoch_length:\n",
        "                loss_rpn_cls = np.mean(losses[:, 0])\n",
        "                loss_rpn_regr = np.mean(losses[:, 1])\n",
        "                loss_class_cls = np.mean(losses[:, 2])\n",
        "                loss_class_regr = np.mean(losses[:, 3])\n",
        "                class_acc = np.mean(losses[:, 4])\n",
        "\n",
        "                mean_overlapping_bboxes = float(sum(rpn_accuracy_for_epoch)) / len(rpn_accuracy_for_epoch)\n",
        "                rpn_accuracy_for_epoch = []\n",
        "\n",
        "                if C.verbose:\n",
        "                    print('Mean number of bounding boxes from RPN overlapping ground truth boxes: {}'.format(mean_overlapping_bboxes))\n",
        "                    print('Classifier accuracy for bounding boxes from RPN: {}'.format(class_acc))\n",
        "                    print('Loss RPN classifier: {}'.format(loss_rpn_cls))\n",
        "                    print('Loss RPN regression: {}'.format(loss_rpn_regr))\n",
        "                    print('Loss Detector classifier: {}'.format(loss_class_cls))\n",
        "                    print('Loss Detector regression: {}'.format(loss_class_regr))\n",
        "                    print('Total loss: {}'.format(loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr))\n",
        "                    print('Elapsed time: {}'.format(time.time() - start_time))\n",
        "                    elapsed_time = (time.time()-start_time)/60\n",
        "\n",
        "                curr_loss = loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr\n",
        "                iter_num = 0\n",
        "                start_time = time.time()\n",
        "\n",
        "                if curr_loss < best_loss:\n",
        "                    if C.verbose:\n",
        "                        print('Total loss decreased from {} to {}, saving weights'.format(best_loss,curr_loss))\n",
        "                    best_loss = curr_loss\n",
        "                    model_all.save_weights(C.model_path)\n",
        "\n",
        "                new_row = {'mean_overlapping_bboxes':round(mean_overlapping_bboxes, 3), \n",
        "                           'class_acc':round(class_acc, 3), \n",
        "                           'loss_rpn_cls':round(loss_rpn_cls, 3), \n",
        "                           'loss_rpn_regr':round(loss_rpn_regr, 3), \n",
        "                           'loss_class_cls':round(loss_class_cls, 3), \n",
        "                           'loss_class_regr':round(loss_class_regr, 3), \n",
        "                           'curr_loss':round(curr_loss, 3), \n",
        "                           'elapsed_time':round(elapsed_time, 3), \n",
        "                           'mAP': 0}\n",
        "\n",
        "                record_df = record_df.append(new_row, ignore_index=True)\n",
        "                record_df.to_csv(record_path, index=0)\n",
        "\n",
        "                break\n",
        "        except Exception as e:\n",
        "            print('Exception: {}'.format(e))\n",
        "            continue\n",
        "        \n",
        "\n",
        "print('Training complete, exiting.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is the first time of your training\n",
            "loading weights from /content/drive/My Drive/Colab Notebooks/model/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "load weights success\n",
            "Epoch 1/40\n",
            "1000/1000 [==============================] - 1325s 1s/step - rpn_cls: 3.5538 - rpn_regr: 0.1540 - final_cls: 1.2020 - final_regr: 0.3952\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 8.678252234359483\n",
            "Classifier accuracy for bounding boxes from RPN: 0.63\n",
            "Loss RPN classifier: 2.7756657770684687\n",
            "Loss RPN regression: 0.14995736240968108\n",
            "Loss Detector classifier: 1.0011112357731908\n",
            "Loss Detector regression: 0.4259589301757514\n",
            "Total loss: 4.352693305427092\n",
            "Elapsed time: 1324.5851707458496\n",
            "Total loss decreased from inf to 4.352693305427092, saving weights\n",
            "Epoch 2/40\n",
            "1000/1000 [==============================] - 1203s 1s/step - rpn_cls: 2.4528 - rpn_regr: 0.1358 - final_cls: 0.7569 - final_regr: 0.4085\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 9.807385229540918\n",
            "Classifier accuracy for bounding boxes from RPN: 0.6575\n",
            "Loss RPN classifier: 2.317980260278644\n",
            "Loss RPN regression: 0.135082756227348\n",
            "Loss Detector classifier: 0.7777981999376788\n",
            "Loss Detector regression: 0.42278797493129966\n",
            "Total loss: 3.6536491913749707\n",
            "Elapsed time: 1203.489259004593\n",
            "Total loss decreased from 4.352693305427092 to 3.6536491913749707, saving weights\n",
            "Epoch 3/40\n",
            "1000/1000 [==============================] - 1201s 1s/step - rpn_cls: 2.0757 - rpn_regr: 0.1409 - final_cls: 0.7174 - final_regr: 0.3930\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 10.035892323030907\n",
            "Classifier accuracy for bounding boxes from RPN: 0.694\n",
            "Loss RPN classifier: 2.2103125829062873\n",
            "Loss RPN regression: 0.14626006430247798\n",
            "Loss Detector classifier: 0.731431414956227\n",
            "Loss Detector regression: 0.39603398234769704\n",
            "Total loss: 3.484038044512689\n",
            "Elapsed time: 1202.0990648269653\n",
            "Total loss decreased from 3.6536491913749707 to 3.484038044512689, saving weights\n",
            "Epoch 4/40\n",
            "1000/1000 [==============================] - 1192s 1s/step - rpn_cls: 1.9686 - rpn_regr: 0.1265 - final_cls: 0.7475 - final_regr: 0.4198\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 10.674325674325674\n",
            "Classifier accuracy for bounding boxes from RPN: 0.691\n",
            "Loss RPN classifier: 1.9772414109029073\n",
            "Loss RPN regression: 0.12887802231125534\n",
            "Loss Detector classifier: 0.730251493897289\n",
            "Loss Detector regression: 0.42395942989364266\n",
            "Total loss: 3.2603303570050945\n",
            "Elapsed time: 1193.0387117862701\n",
            "Total loss decreased from 3.484038044512689 to 3.2603303570050945, saving weights\n",
            "Epoch 5/40\n",
            "1000/1000 [==============================] - 835s 835ms/step - rpn_cls: 1.8067 - rpn_regr: 0.1350 - final_cls: 0.7014 - final_regr: 0.4109\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 11.076\n",
            "Classifier accuracy for bounding boxes from RPN: 0.708\n",
            "Loss RPN classifier: 1.8036611045567557\n",
            "Loss RPN regression: 0.1362135222693905\n",
            "Loss Detector classifier: 0.6933579647243023\n",
            "Loss Detector regression: 0.40050810016691685\n",
            "Total loss: 3.0337406917173655\n",
            "Elapsed time: 836.6401987075806\n",
            "Total loss decreased from 3.2603303570050945 to 3.0337406917173655, saving weights\n",
            "Epoch 6/40\n",
            "1000/1000 [==============================] - 795s 795ms/step - rpn_cls: 1.6966 - rpn_regr: 0.1305 - final_cls: 0.6751 - final_regr: 0.3859\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 11.377\n",
            "Classifier accuracy for bounding boxes from RPN: 0.699\n",
            "Loss RPN classifier: 1.7604377942589002\n",
            "Loss RPN regression: 0.12375213385466487\n",
            "Loss Detector classifier: 0.6931779042892158\n",
            "Loss Detector regression: 0.3905882263388485\n",
            "Total loss: 2.9679560587416294\n",
            "Elapsed time: 797.2788624763489\n",
            "Total loss decreased from 3.0337406917173655 to 2.9679560587416294, saving weights\n",
            "Epoch 7/40\n",
            "1000/1000 [==============================] - 817s 817ms/step - rpn_cls: 1.7389 - rpn_regr: 0.1290 - final_cls: 0.6629 - final_regr: 0.3691\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 11.657\n",
            "Classifier accuracy for bounding boxes from RPN: 0.71375\n",
            "Loss RPN classifier: 1.7887162982323708\n",
            "Loss RPN regression: 0.13382601907406932\n",
            "Loss Detector classifier: 0.6580261465907097\n",
            "Loss Detector regression: 0.37701586150750516\n",
            "Total loss: 2.957584325404655\n",
            "Elapsed time: 818.4071371555328\n",
            "Total loss decreased from 2.9679560587416294 to 2.957584325404655, saving weights\n",
            "Epoch 8/40\n",
            "1000/1000 [==============================] - 795s 795ms/step - rpn_cls: 1.8349 - rpn_regr: 0.1291 - final_cls: 0.6586 - final_regr: 0.3663\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 11.593406593406593\n",
            "Classifier accuracy for bounding boxes from RPN: 0.7275\n",
            "Loss RPN classifier: 1.737623148164094\n",
            "Loss RPN regression: 0.12153096144460142\n",
            "Loss Detector classifier: 0.6444363083653152\n",
            "Loss Detector regression: 0.3701649928241968\n",
            "Total loss: 2.873755410798207\n",
            "Elapsed time: 796.6502315998077\n",
            "Total loss decreased from 2.957584325404655 to 2.873755410798207, saving weights\n",
            "Epoch 9/40\n",
            "1000/1000 [==============================] - 806s 806ms/step - rpn_cls: 1.6966 - rpn_regr: 0.1316 - final_cls: 0.6317 - final_regr: 0.3608\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 12.177\n",
            "Classifier accuracy for bounding boxes from RPN: 0.72825\n",
            "Loss RPN classifier: 1.634339725758187\n",
            "Loss RPN regression: 0.12897927445895038\n",
            "Loss Detector classifier: 0.6319856235329062\n",
            "Loss Detector regression: 0.3581621829848737\n",
            "Total loss: 2.7534668067349175\n",
            "Elapsed time: 807.8426470756531\n",
            "Total loss decreased from 2.873755410798207 to 2.7534668067349175, saving weights\n",
            "Epoch 10/40\n",
            "1000/1000 [==============================] - 784s 784ms/step - rpn_cls: 1.7088 - rpn_regr: 0.1237 - final_cls: 0.6038 - final_regr: 0.3566\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 11.798\n",
            "Classifier accuracy for bounding boxes from RPN: 0.74675\n",
            "Loss RPN classifier: 1.6673672228256868\n",
            "Loss RPN regression: 0.11746849784534424\n",
            "Loss Detector classifier: 0.6083615691866726\n",
            "Loss Detector regression: 0.3501751910932362\n",
            "Total loss: 2.74337248095094\n",
            "Elapsed time: 785.7921261787415\n",
            "Total loss decreased from 2.7534668067349175 to 2.74337248095094, saving weights\n",
            "Epoch 11/40\n",
            "1000/1000 [==============================] - 812s 812ms/step - rpn_cls: 1.6676 - rpn_regr: 0.1274 - final_cls: 0.6295 - final_regr: 0.3461\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 12.10179640718563\n",
            "Classifier accuracy for bounding boxes from RPN: 0.7505\n",
            "Loss RPN classifier: 1.7371722259023734\n",
            "Loss RPN regression: 0.13010045905061998\n",
            "Loss Detector classifier: 0.6123174636978657\n",
            "Loss Detector regression: 0.34331341308820995\n",
            "Total loss: 2.822903561739069\n",
            "Elapsed time: 813.9773805141449\n",
            "Epoch 12/40\n",
            "1000/1000 [==============================] - 798s 798ms/step - rpn_cls: 1.6971 - rpn_regr: 0.1171 - final_cls: 0.6509 - final_regr: 0.3367\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 12.2375249500998\n",
            "Classifier accuracy for bounding boxes from RPN: 0.73025\n",
            "Loss RPN classifier: 1.6814215114757036\n",
            "Loss RPN regression: 0.11684245624626055\n",
            "Loss Detector classifier: 0.626044317079708\n",
            "Loss Detector regression: 0.33170680664665997\n",
            "Total loss: 2.756015091448332\n",
            "Elapsed time: 798.2005870342255\n",
            "Epoch 13/40\n",
            "1000/1000 [==============================] - 794s 794ms/step - rpn_cls: 1.7075 - rpn_regr: 0.1227 - final_cls: 0.6049 - final_regr: 0.3253\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 12.056\n",
            "Classifier accuracy for bounding boxes from RPN: 0.7515\n",
            "Loss RPN classifier: 1.6500679316453142\n",
            "Loss RPN regression: 0.1250036598208826\n",
            "Loss Detector classifier: 0.59032458942011\n",
            "Loss Detector regression: 0.31724760858528317\n",
            "Total loss: 2.68264378947159\n",
            "Elapsed time: 793.8822114467621\n",
            "Total loss decreased from 2.74337248095094 to 2.68264378947159, saving weights\n",
            "Epoch 14/40\n",
            "1000/1000 [==============================] - 787s 787ms/step - rpn_cls: 1.5411 - rpn_regr: 0.1210 - final_cls: 0.6294 - final_regr: 0.3123\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 12.579\n",
            "Classifier accuracy for bounding boxes from RPN: 0.743\n",
            "Loss RPN classifier: 1.5447709685242805\n",
            "Loss RPN regression: 0.11740553085925058\n",
            "Loss Detector classifier: 0.601888961866498\n",
            "Loss Detector regression: 0.30978459249809387\n",
            "Total loss: 2.5738500537481226\n",
            "Elapsed time: 788.7287678718567\n",
            "Total loss decreased from 2.68264378947159 to 2.5738500537481226, saving weights\n",
            "Epoch 15/40\n",
            "1000/1000 [==============================] - 800s 800ms/step - rpn_cls: 1.5688 - rpn_regr: 0.1164 - final_cls: 0.6015 - final_regr: 0.3040\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 12.341658341658341\n",
            "Classifier accuracy for bounding boxes from RPN: 0.75525\n",
            "Loss RPN classifier: 1.6069737726426274\n",
            "Loss RPN regression: 0.12351447004568764\n",
            "Loss Detector classifier: 0.5649810627978296\n",
            "Loss Detector regression: 0.30450760331191123\n",
            "Total loss: 2.5999769087980558\n",
            "Elapsed time: 802.2828712463379\n",
            "Epoch 16/40\n",
            "1000/1000 [==============================] - 792s 792ms/step - rpn_cls: 1.7431 - rpn_regr: 0.1249 - final_cls: 0.5632 - final_regr: 0.3049\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 12.212787212787212\n",
            "Classifier accuracy for bounding boxes from RPN: 0.7635\n",
            "Loss RPN classifier: 1.631139878994864\n",
            "Loss RPN regression: 0.1158668414199492\n",
            "Loss Detector classifier: 0.582203743705526\n",
            "Loss Detector regression: 0.29405409932509063\n",
            "Total loss: 2.6232645634454297\n",
            "Elapsed time: 792.4876458644867\n",
            "Epoch 17/40\n",
            "1000/1000 [==============================] - 790s 790ms/step - rpn_cls: 1.8006 - rpn_regr: 0.1246 - final_cls: 0.5732 - final_regr: 0.3086\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 12.198\n",
            "Classifier accuracy for bounding boxes from RPN: 0.75875\n",
            "Loss RPN classifier: 1.6201519120918024\n",
            "Loss RPN regression: 0.12172191875777208\n",
            "Loss Detector classifier: 0.5729611247144639\n",
            "Loss Detector regression: 0.30255460979044435\n",
            "Total loss: 2.6173895653544825\n",
            "Elapsed time: 790.5082025527954\n",
            "Epoch 18/40\n",
            "1000/1000 [==============================] - 777s 777ms/step - rpn_cls: 1.5428 - rpn_regr: 0.1270 - final_cls: 0.5465 - final_regr: 0.3027\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 12.721\n",
            "Classifier accuracy for bounding boxes from RPN: 0.7655\n",
            "Loss RPN classifier: 1.5106032552354591\n",
            "Loss RPN regression: 0.1171076251610648\n",
            "Loss Detector classifier: 0.5610428071469069\n",
            "Loss Detector regression: 0.2952219259198755\n",
            "Total loss: 2.4839756134633064\n",
            "Elapsed time: 777.1504559516907\n",
            "Total loss decreased from 2.5738500537481226 to 2.4839756134633064, saving weights\n",
            "Epoch 19/40\n",
            "1000/1000 [==============================] - 794s 794ms/step - rpn_cls: 1.4389 - rpn_regr: 0.1126 - final_cls: 0.5443 - final_regr: 0.2818\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 12.377622377622378\n",
            "Classifier accuracy for bounding boxes from RPN: 0.77\n",
            "Loss RPN classifier: 1.5557543853488862\n",
            "Loss RPN regression: 0.11975514309364371\n",
            "Loss Detector classifier: 0.5465855621397495\n",
            "Loss Detector regression: 0.28325362839736046\n",
            "Total loss: 2.50534871897964\n",
            "Elapsed time: 795.9091610908508\n",
            "Epoch 20/40\n",
            "1000/1000 [==============================] - 796s 796ms/step - rpn_cls: 1.6775 - rpn_regr: 0.1206 - final_cls: 0.5757 - final_regr: 0.3064\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 12.284715284715285\n",
            "Classifier accuracy for bounding boxes from RPN: 0.76225\n",
            "Loss RPN classifier: 1.5184258669967154\n",
            "Loss RPN regression: 0.11442403891356662\n",
            "Loss Detector classifier: 0.565419469319284\n",
            "Loss Detector regression: 0.29052505327761174\n",
            "Total loss: 2.488794428507178\n",
            "Elapsed time: 796.2266154289246\n",
            "Epoch 21/40\n",
            " 918/1000 [==========================>...] - ETA: 1:05 - rpn_cls: 1.7163 - rpn_regr: 0.1187 - final_cls: 0.5669 - final_regr: 0.2941Exception: 'a' cannot be empty unless no samples are taken\n",
            "1000/1000 [==============================] - 794s 794ms/step - rpn_cls: 1.7131 - rpn_regr: 0.1190 - final_cls: 0.5664 - final_regr: 0.2935\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 13.071856287425149\n",
            "Classifier accuracy for bounding boxes from RPN: 0.76375\n",
            "Loss RPN classifier: 1.6594104438226855\n",
            "Loss RPN regression: 0.12045044991443865\n",
            "Loss Detector classifier: 0.5608864438445307\n",
            "Loss Detector regression: 0.2861808174881153\n",
            "Total loss: 2.62692815506977\n",
            "Elapsed time: 794.2359621524811\n",
            "Epoch 22/40\n",
            "1000/1000 [==============================] - 783s 783ms/step - rpn_cls: 1.5265 - rpn_regr: 0.1192 - final_cls: 0.5658 - final_regr: 0.2877\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 12.516\n",
            "Classifier accuracy for bounding boxes from RPN: 0.769\n",
            "Loss RPN classifier: 1.432071871563456\n",
            "Loss RPN regression: 0.11509377282857895\n",
            "Loss Detector classifier: 0.5424094130313024\n",
            "Loss Detector regression: 0.29141691931337116\n",
            "Total loss: 2.3809919767367083\n",
            "Elapsed time: 782.8051736354828\n",
            "Total loss decreased from 2.4839756134633064 to 2.3809919767367083, saving weights\n",
            "Epoch 23/40\n",
            " 361/1000 [=========>....................] - ETA: 8:18 - rpn_cls: 1.6317 - rpn_regr: 0.1105 - final_cls: 0.4803 - final_regr: 0.2671Exception: 'a' cannot be empty unless no samples are taken\n",
            "1000/1000 [==============================] - 794s 794ms/step - rpn_cls: 1.5662 - rpn_regr: 0.1121 - final_cls: 0.4983 - final_regr: 0.2756\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 12.625374625374626\n",
            "Classifier accuracy for bounding boxes from RPN: 0.79675\n",
            "Loss RPN classifier: 1.5243752225288036\n",
            "Loss RPN regression: 0.117022623505909\n",
            "Loss Detector classifier: 0.49601548758428543\n",
            "Loss Detector regression: 0.2803210464967415\n",
            "Total loss: 2.4177343801157396\n",
            "Elapsed time: 795.4591829776764\n",
            "Epoch 24/40\n",
            "1000/1000 [==============================] - 809s 809ms/step - rpn_cls: 1.7010 - rpn_regr: 0.1169 - final_cls: 0.5337 - final_regr: 0.2768\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 12.732267732267733\n",
            "Classifier accuracy for bounding boxes from RPN: 0.7715\n",
            "Loss RPN classifier: 1.5711815460964087\n",
            "Loss RPN regression: 0.11471670965570957\n",
            "Loss Detector classifier: 0.5360129155516624\n",
            "Loss Detector regression: 0.27631114997807893\n",
            "Total loss: 2.4982223212818595\n",
            "Elapsed time: 808.7978994846344\n",
            "Epoch 25/40\n",
            "1000/1000 [==============================] - 796s 796ms/step - rpn_cls: 1.5684 - rpn_regr: 0.1147 - final_cls: 0.5590 - final_regr: 0.2807\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 12.659\n",
            "Classifier accuracy for bounding boxes from RPN: 0.76725\n",
            "Loss RPN classifier: 1.5653688114873257\n",
            "Loss RPN regression: 0.1189918923068326\n",
            "Loss Detector classifier: 0.5652308834353462\n",
            "Loss Detector regression: 0.27441187428776176\n",
            "Total loss: 2.5240034615172666\n",
            "Elapsed time: 795.8927068710327\n",
            "Epoch 26/40\n",
            "1000/1000 [==============================] - 792s 792ms/step - rpn_cls: 1.3939 - rpn_regr: 0.1140 - final_cls: 0.5054 - final_regr: 0.2530\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 12.716283716283716\n",
            "Classifier accuracy for bounding boxes from RPN: 0.79\n",
            "Loss RPN classifier: 1.4265246375207652\n",
            "Loss RPN regression: 0.11482635912683327\n",
            "Loss Detector classifier: 0.5081861241171136\n",
            "Loss Detector regression: 0.2588642376624048\n",
            "Total loss: 2.308401358427117\n",
            "Elapsed time: 791.735832452774\n",
            "Total loss decreased from 2.3809919767367083 to 2.308401358427117, saving weights\n",
            "Epoch 27/40\n",
            "1000/1000 [==============================] - 788s 788ms/step - rpn_cls: 1.4643 - rpn_regr: 0.1041 - final_cls: 0.5271 - final_regr: 0.2696\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 12.746253746253746\n",
            "Classifier accuracy for bounding boxes from RPN: 0.78625\n",
            "Loss RPN classifier: 1.3850813190970106\n",
            "Loss RPN regression: 0.11121097842627205\n",
            "Loss Detector classifier: 0.5025186205683276\n",
            "Loss Detector regression: 0.2666410242207348\n",
            "Total loss: 2.265451942312345\n",
            "Elapsed time: 790.2762253284454\n",
            "Total loss decreased from 2.308401358427117 to 2.265451942312345, saving weights\n",
            "Epoch 28/40\n",
            "1000/1000 [==============================] - 806s 806ms/step - rpn_cls: 1.5870 - rpn_regr: 0.1218 - final_cls: 0.4923 - final_regr: 0.2667\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 12.616151545363909\n",
            "Classifier accuracy for bounding boxes from RPN: 0.7875\n",
            "Loss RPN classifier: 1.4649947596624753\n",
            "Loss RPN regression: 0.1149243209711276\n",
            "Loss Detector classifier: 0.5079239393114112\n",
            "Loss Detector regression: 0.264431192137301\n",
            "Total loss: 2.352274212082315\n",
            "Elapsed time: 807.7842693328857\n",
            "Epoch 29/40\n",
            "1000/1000 [==============================] - 799s 799ms/step - rpn_cls: 1.3389 - rpn_regr: 0.1106 - final_cls: 0.5336 - final_regr: 0.2782\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 13.188\n",
            "Classifier accuracy for bounding boxes from RPN: 0.766\n",
            "Loss RPN classifier: 1.4026755812088416\n",
            "Loss RPN regression: 0.11603897912683897\n",
            "Loss Detector classifier: 0.5411397046167403\n",
            "Loss Detector regression: 0.2702632601074874\n",
            "Total loss: 2.3301175250599084\n",
            "Elapsed time: 798.6130228042603\n",
            "Epoch 30/40\n",
            "1000/1000 [==============================] - 795s 795ms/step - rpn_cls: 1.2736 - rpn_regr: 0.1148 - final_cls: 0.5422 - final_regr: 0.2647\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 12.820359281437126\n",
            "Classifier accuracy for bounding boxes from RPN: 0.77875\n",
            "Loss RPN classifier: 1.275077966230304\n",
            "Loss RPN regression: 0.11439329104567877\n",
            "Loss Detector classifier: 0.5260023054657504\n",
            "Loss Detector regression: 0.26011547220125797\n",
            "Total loss: 2.175589034942991\n",
            "Elapsed time: 794.9867343902588\n",
            "Total loss decreased from 2.265451942312345 to 2.175589034942991, saving weights\n",
            "Epoch 31/40\n",
            "  14/1000 [..............................] - ETA: 13:42 - rpn_cls: 1.3885 - rpn_regr: 0.1186 - final_cls: 0.5271 - final_regr: 0.2322"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-7d8abac8d41f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    141\u001b[0m                     \u001b[0msel_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mloss_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msel_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mY1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msel_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msel_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miter_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_rpn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3798\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3799\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3800\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3801\u001b[0m         expand_composites=True)\n\u001b[1;32m   3802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3798\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3799\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3800\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3801\u001b[0m         expand_composites=True)\n\u001b[1;32m   3802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}