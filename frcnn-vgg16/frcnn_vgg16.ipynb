{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "frcnn_vgg16.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktCVTF2sorIm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "288c3ed1-3749-44ab-810d-8216c4410f50"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foTB0duy1dH_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a192c58e-c6f2-4069-de1f-fa47023c8d9f"
      },
      "source": [
        "import json\n",
        "import random\n",
        "import pprint\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "from optparse import OptionParser\n",
        "import pickle\n",
        "import math\n",
        "import cv2\n",
        "import copy\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam, SGD, RMSprop\n",
        "from keras.layers import Flatten, Dense, Input, Conv2D, MaxPooling2D, Dropout\n",
        "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, TimeDistributed\n",
        "from keras.engine.topology import get_source_inputs\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.objectives import categorical_crossentropy\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.utils import generic_utils\n",
        "from keras.engine import Layer, InputSpec\n",
        "from keras import initializers, regularizers\n",
        "\n",
        "class Config:\n",
        "\n",
        "\tdef __init__(self):\n",
        "\n",
        "\t\tself.verbose = True\n",
        "\t\tself.network = 'vgg'\n",
        "\t\tself.use_horizontal_flips = False\n",
        "\t\tself.use_vertical_flips = False\n",
        "\t\tself.rot_90 = False\n",
        "\n",
        "\t\tself.anchor_box_scales = [64, 128, 256] \n",
        "\n",
        "\t\tself.anchor_box_ratios = [[1, 1], [1./math.sqrt(2), 2./math.sqrt(2)], [2./math.sqrt(2), 1./math.sqrt(2)]]\n",
        "\n",
        "\t\tself.im_size = 300\n",
        "\t\tself.img_channel_mean = [103.939, 116.779, 123.68]\n",
        "\t\tself.img_scaling_factor = 1.0\n",
        "\t\tself.num_rois = 4\n",
        "\t\tself.rpn_stride = 16\n",
        "\n",
        "\t\tself.balanced_classes = False\n",
        "\n",
        "\t\tself.std_scaling = 4.0\n",
        "\t\tself.classifier_regr_std = [8.0, 8.0, 4.0, 4.0]\n",
        "\n",
        "\t\tself.rpn_min_overlap = 0.3\n",
        "\t\tself.rpn_max_overlap = 0.7\n",
        "\n",
        "\t\tself.classifier_min_overlap = 0.1\n",
        "\t\tself.classifier_max_overlap = 0.5\n",
        "\t\tself.class_mapping = None\n",
        "\n",
        "\t\tself.model_path = None\n",
        "\n",
        "def get_data(basePath = '/content/drive/My Drive/Colab Notebooks/'):\n",
        "    all_imgs = {}\n",
        "    classes_count = {}\n",
        "    class_mapping = {}\n",
        "\n",
        "    with open(basePath + \"dataInfo.json\",'r') as file:\n",
        "        all_imgs = json.load(fp = file)\n",
        "    with open(basePath + \"classes_count.json\",'r') as file:\n",
        "        classes_count = json.load(fp = file)\n",
        "    with open(basePath + \"class_mapping.json\",'r') as file:\n",
        "        class_mapping = json.load(fp = file)\n",
        "    \n",
        "    all_data = []\n",
        "    for key in all_imgs:\n",
        "        all_data.append(all_imgs[key])\n",
        "\t\t\t\n",
        "    return all_data, classes_count, class_mapping"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYEgSvnD5jZd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def union(au, bu, area_intersection):\n",
        "\tarea_a = (au[2] - au[0]) * (au[3] - au[1])\n",
        "\tarea_b = (bu[2] - bu[0]) * (bu[3] - bu[1])\n",
        "\tarea_union = area_a + area_b - area_intersection\n",
        "\treturn area_union\n",
        "\n",
        "\n",
        "def intersection(ai, bi):\n",
        "\tx = max(ai[0], bi[0])\n",
        "\ty = max(ai[1], bi[1])\n",
        "\tw = min(ai[2], bi[2]) - x\n",
        "\th = min(ai[3], bi[3]) - y\n",
        "\tif w < 0 or h < 0:\n",
        "\t\treturn 0\n",
        "\treturn w*h\n",
        "\n",
        "\n",
        "def iou(a, b):\n",
        "\n",
        "\tif a[0] >= a[2] or a[1] >= a[3] or b[0] >= b[2] or b[1] >= b[3]:\n",
        "\t\treturn 0.0\n",
        "\n",
        "\tarea_i = intersection(a, b)\n",
        "\tarea_u = union(a, b, area_i)\n",
        "\n",
        "\treturn float(area_i) / float(area_u + 1e-6)\n",
        "\n",
        "def calc_rpn(C, img_data, width, height, resized_width, resized_height, img_length_calc_function):\n",
        "\t\n",
        "\tdownscale = float(C.rpn_stride) \n",
        "\tanchor_sizes = C.anchor_box_scales   \n",
        "\tanchor_ratios = C.anchor_box_ratios  \n",
        "\tnum_anchors = len(anchor_sizes) * len(anchor_ratios) \n",
        "\n",
        "\t(output_width, output_height) = img_length_calc_function(resized_width, resized_height)\n",
        "\n",
        "\tn_anchratios = len(anchor_ratios)    \n",
        "\t\n",
        "\ty_rpn_overlap = np.zeros((output_height, output_width, num_anchors))\n",
        "\ty_is_box_valid = np.zeros((output_height, output_width, num_anchors))\n",
        "\ty_rpn_regr = np.zeros((output_height, output_width, num_anchors * 4))\n",
        "\n",
        "\tnum_bboxes = len(img_data['bboxes'])\n",
        "\n",
        "\tnum_anchors_for_bbox = np.zeros(num_bboxes).astype(int)\n",
        "\tbest_anchor_for_bbox = -1*np.ones((num_bboxes, 4)).astype(int)\n",
        "\tbest_iou_for_bbox = np.zeros(num_bboxes).astype(np.float32)\n",
        "\tbest_x_for_bbox = np.zeros((num_bboxes, 4)).astype(int)\n",
        "\tbest_dx_for_bbox = np.zeros((num_bboxes, 4)).astype(np.float32)\n",
        "\n",
        "\tgta = np.zeros((num_bboxes, 4))\n",
        "\tfor bbox_num, bbox in enumerate(img_data['bboxes']):\n",
        "\t\tgta[bbox_num, 0] = bbox['x1'] * (resized_width / float(width))\n",
        "\t\tgta[bbox_num, 1] = bbox['x2'] * (resized_width / float(width))\n",
        "\t\tgta[bbox_num, 2] = bbox['y1'] * (resized_height / float(height))\n",
        "\t\tgta[bbox_num, 3] = bbox['y2'] * (resized_height / float(height))\n",
        "\n",
        "\tfor anchor_size_idx in range(len(anchor_sizes)):\n",
        "\t\tfor anchor_ratio_idx in range(n_anchratios):\n",
        "\t\t\tanchor_x = anchor_sizes[anchor_size_idx] * anchor_ratios[anchor_ratio_idx][0]\n",
        "\t\t\tanchor_y = anchor_sizes[anchor_size_idx] * anchor_ratios[anchor_ratio_idx][1]\t\n",
        "\t\t\t\n",
        "\t\t\tfor ix in range(output_width):\t\t\t\t\t\n",
        "\t\t\n",
        "\t\t\t\tx1_anc = downscale * (ix + 0.5) - anchor_x / 2\n",
        "\t\t\t\tx2_anc = downscale * (ix + 0.5) + anchor_x / 2\t\n",
        "\t\t\t\t\t\t\t\n",
        "\t\t\t\tif x1_anc < 0 or x2_anc > resized_width:\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\t\t\n",
        "\t\t\t\tfor jy in range(output_height):\n",
        "\t\t\t\t\ty1_anc = downscale * (jy + 0.5) - anchor_y / 2\n",
        "\t\t\t\t\ty2_anc = downscale * (jy + 0.5) + anchor_y / 2\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\tif y1_anc < 0 or y2_anc > resized_height:\n",
        "\t\t\t\t\t\tcontinue\n",
        "\n",
        "\t\t\t\t\tbbox_type = 'neg'\n",
        "\t\t\t\t\tbest_iou_for_loc = 0.0\n",
        "\n",
        "\t\t\t\t\tfor bbox_num in range(num_bboxes):\n",
        "\t\t\t\t\t\tcurr_iou = iou([gta[bbox_num, 0], gta[bbox_num, 2], gta[bbox_num, 1], gta[bbox_num, 3]], [x1_anc, y1_anc, x2_anc, y2_anc])\n",
        "\t\t\t\t\t\tif curr_iou > best_iou_for_bbox[bbox_num] or curr_iou > C.rpn_max_overlap:\n",
        "\t\t\t\t\t\t\tcx = (gta[bbox_num, 0] + gta[bbox_num, 1]) / 2.0\n",
        "\t\t\t\t\t\t\tcy = (gta[bbox_num, 2] + gta[bbox_num, 3]) / 2.0\n",
        "\t\t\t\t\t\t\tcxa = (x1_anc + x2_anc)/2.0\n",
        "\t\t\t\t\t\t\tcya = (y1_anc + y2_anc)/2.0\n",
        "\n",
        "\t\t\t\t\t\t\ttx = (cx - cxa) / (x2_anc - x1_anc)\n",
        "\t\t\t\t\t\t\tty = (cy - cya) / (y2_anc - y1_anc)\n",
        "\t\t\t\t\t\t\ttw = np.log((gta[bbox_num, 1] - gta[bbox_num, 0]) / (x2_anc - x1_anc))\n",
        "\t\t\t\t\t\t\tth = np.log((gta[bbox_num, 3] - gta[bbox_num, 2]) / (y2_anc - y1_anc))\n",
        "\t\t\t\t\t\t\n",
        "\t\t\t\t\t\tif img_data['bboxes'][bbox_num]['class'] != 'bg':\n",
        "\t\t\t\t\t\t\tif curr_iou > best_iou_for_bbox[bbox_num]:\n",
        "\t\t\t\t\t\t\t\tbest_anchor_for_bbox[bbox_num] = [jy, ix, anchor_ratio_idx, anchor_size_idx]\n",
        "\t\t\t\t\t\t\t\tbest_iou_for_bbox[bbox_num] = curr_iou\n",
        "\t\t\t\t\t\t\t\tbest_x_for_bbox[bbox_num,:] = [x1_anc, x2_anc, y1_anc, y2_anc]\n",
        "\t\t\t\t\t\t\t\tbest_dx_for_bbox[bbox_num,:] = [tx, ty, tw, th]\n",
        "\n",
        "\t\t\t\t\t\t\tif curr_iou > C.rpn_max_overlap:\n",
        "\t\t\t\t\t\t\t\tbbox_type = 'pos'\n",
        "\t\t\t\t\t\t\t\tnum_anchors_for_bbox[bbox_num] += 1\n",
        "\t\t\t\t\t\t\t\tif curr_iou > best_iou_for_loc:\n",
        "\t\t\t\t\t\t\t\t\tbest_iou_for_loc = curr_iou\n",
        "\t\t\t\t\t\t\t\t\tbest_regr = (tx, ty, tw, th)\n",
        "\t\t \n",
        "\t\t\t\t\t\t\tif C.rpn_min_overlap < curr_iou < C.rpn_max_overlap:\n",
        "\t\t\t\t\t\t\t\tif bbox_type != 'pos':\n",
        "\t\t\t\t\t\t\t\t\tbbox_type = 'neutral'\n",
        "\n",
        "\t\t\t\t\tif bbox_type == 'neg':\n",
        "\t\t\t\t\t\ty_is_box_valid[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 1\n",
        "\t\t\t\t\t\ty_rpn_overlap[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 0\n",
        "\t\t\t\t\telif bbox_type == 'neutral':\n",
        "\t\t\t\t\t\ty_is_box_valid[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 0\n",
        "\t\t\t\t\t\ty_rpn_overlap[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 0\n",
        "\t\t\t\t\telif bbox_type == 'pos':\n",
        "\t\t\t\t\t\ty_is_box_valid[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 1\n",
        "\t\t\t\t\t\ty_rpn_overlap[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 1\n",
        "\t\t\t\t\t\tstart = 4 * (anchor_ratio_idx + n_anchratios * anchor_size_idx)\n",
        "\t\t\t\t\t\ty_rpn_regr[jy, ix, start:start+4] = best_regr\n",
        "\n",
        "\tfor idx in range(num_anchors_for_bbox.shape[0]):\n",
        "\t\tif num_anchors_for_bbox[idx] == 0:\n",
        "\t\t\tif best_anchor_for_bbox[idx, 0] == -1:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\ty_is_box_valid[\n",
        "\t\t\t\tbest_anchor_for_bbox[idx,0], best_anchor_for_bbox[idx,1], best_anchor_for_bbox[idx,2] + n_anchratios *\n",
        "\t\t\t\tbest_anchor_for_bbox[idx,3]] = 1\n",
        "\t\t\ty_rpn_overlap[\n",
        "\t\t\t\tbest_anchor_for_bbox[idx,0], best_anchor_for_bbox[idx,1], best_anchor_for_bbox[idx,2] + n_anchratios *\n",
        "\t\t\t\tbest_anchor_for_bbox[idx,3]] = 1\n",
        "\t\t\tstart = 4 * (best_anchor_for_bbox[idx,2] + n_anchratios * best_anchor_for_bbox[idx,3])\n",
        "\t\t\ty_rpn_regr[\n",
        "\t\t\t\tbest_anchor_for_bbox[idx,0], best_anchor_for_bbox[idx,1], start:start+4] = best_dx_for_bbox[idx, :]\n",
        "\n",
        "\ty_rpn_overlap = np.transpose(y_rpn_overlap, (2, 0, 1))\n",
        "\ty_rpn_overlap = np.expand_dims(y_rpn_overlap, axis=0)\n",
        "\n",
        "\ty_is_box_valid = np.transpose(y_is_box_valid, (2, 0, 1))\n",
        "\ty_is_box_valid = np.expand_dims(y_is_box_valid, axis=0)\n",
        "\n",
        "\ty_rpn_regr = np.transpose(y_rpn_regr, (2, 0, 1))\n",
        "\ty_rpn_regr = np.expand_dims(y_rpn_regr, axis=0)\n",
        "\n",
        "\tpos_locs = np.where(np.logical_and(y_rpn_overlap[0, :, :, :] == 1, y_is_box_valid[0, :, :, :] == 1))\n",
        "\tneg_locs = np.where(np.logical_and(y_rpn_overlap[0, :, :, :] == 0, y_is_box_valid[0, :, :, :] == 1))\n",
        "\n",
        "\tnum_pos = len(pos_locs[0])\n",
        "\n",
        "\tnum_regions = 256\n",
        "\n",
        "\tif len(pos_locs[0]) > num_regions/2:\n",
        "\t\tval_locs = random.sample(range(len(pos_locs[0])), len(pos_locs[0]) - num_regions/2)\n",
        "\t\ty_is_box_valid[0, pos_locs[0][val_locs], pos_locs[1][val_locs], pos_locs[2][val_locs]] = 0\n",
        "\t\tnum_pos = num_regions/2\n",
        "\n",
        "\tif len(neg_locs[0]) + num_pos > num_regions:\n",
        "\t\tval_locs = random.sample(range(len(neg_locs[0])), len(neg_locs[0]) - num_pos)\n",
        "\t\ty_is_box_valid[0, neg_locs[0][val_locs], neg_locs[1][val_locs], neg_locs[2][val_locs]] = 0\n",
        "\n",
        "\ty_rpn_cls = np.concatenate([y_is_box_valid, y_rpn_overlap], axis=1)\n",
        "\ty_rpn_regr = np.concatenate([np.repeat(y_rpn_overlap, 4, axis=1), y_rpn_regr], axis=1)\n",
        "\n",
        "\treturn np.copy(y_rpn_cls), np.copy(y_rpn_regr), num_pos\n",
        "\n",
        "def get_new_img_size(width, height, img_min_side=300):\n",
        "\tif width <= height:\n",
        "\t\tf = float(img_min_side) / width\n",
        "\t\tresized_height = int(f * height)\n",
        "\t\tresized_width = img_min_side\n",
        "\telse:\n",
        "\t\tf = float(img_min_side) / height\n",
        "\t\tresized_width = int(f * width)\n",
        "\t\tresized_height = img_min_side\n",
        "\n",
        "\treturn resized_width, resized_height\n",
        "\n",
        "def augment(img_data, config, augment=True):\n",
        "\tassert 'filepath' in img_data\n",
        "\tassert 'bboxes' in img_data\n",
        "\tassert 'width' in img_data\n",
        "\tassert 'height' in img_data\n",
        "\n",
        "\timg_data_aug = copy.deepcopy(img_data)\n",
        "\n",
        "\timg = cv2.imread(img_data_aug['filepath'])\n",
        "\n",
        "\tif augment:\n",
        "\t\trows, cols = img.shape[:2]\n",
        "\n",
        "\t\tif config.use_horizontal_flips and np.random.randint(0, 2) == 0:\n",
        "\t\t\timg = cv2.flip(img, 1)\n",
        "\t\t\tfor bbox in img_data_aug['bboxes']:\n",
        "\t\t\t\tx1 = bbox['x1']\n",
        "\t\t\t\tx2 = bbox['x2']\n",
        "\t\t\t\tbbox['x2'] = cols - x1\n",
        "\t\t\t\tbbox['x1'] = cols - x2\n",
        "\n",
        "\t\tif config.use_vertical_flips and np.random.randint(0, 2) == 0:\n",
        "\t\t\timg = cv2.flip(img, 0)\n",
        "\t\t\tfor bbox in img_data_aug['bboxes']:\n",
        "\t\t\t\ty1 = bbox['y1']\n",
        "\t\t\t\ty2 = bbox['y2']\n",
        "\t\t\t\tbbox['y2'] = rows - y1\n",
        "\t\t\t\tbbox['y1'] = rows - y2\n",
        "\n",
        "\t\tif config.rot_90:\n",
        "\t\t\tangle = np.random.choice([0,90,180,270],1)[0]\n",
        "\t\t\tif angle == 270:\n",
        "\t\t\t\timg = np.transpose(img, (1,0,2))\n",
        "\t\t\t\timg = cv2.flip(img, 0)\n",
        "\t\t\telif angle == 180:\n",
        "\t\t\t\timg = cv2.flip(img, -1)\n",
        "\t\t\telif angle == 90:\n",
        "\t\t\t\timg = np.transpose(img, (1,0,2))\n",
        "\t\t\t\timg = cv2.flip(img, 1)\n",
        "\t\t\telif angle == 0:\n",
        "\t\t\t\tpass\n",
        "\n",
        "\t\t\tfor bbox in img_data_aug['bboxes']:\n",
        "\t\t\t\tx1 = bbox['x1']\n",
        "\t\t\t\tx2 = bbox['x2']\n",
        "\t\t\t\ty1 = bbox['y1']\n",
        "\t\t\t\ty2 = bbox['y2']\n",
        "\t\t\t\tif angle == 270:\n",
        "\t\t\t\t\tbbox['x1'] = y1\n",
        "\t\t\t\t\tbbox['x2'] = y2\n",
        "\t\t\t\t\tbbox['y1'] = cols - x2\n",
        "\t\t\t\t\tbbox['y2'] = cols - x1\n",
        "\t\t\t\telif angle == 180:\n",
        "\t\t\t\t\tbbox['x2'] = cols - x1\n",
        "\t\t\t\t\tbbox['x1'] = cols - x2\n",
        "\t\t\t\t\tbbox['y2'] = rows - y1\n",
        "\t\t\t\t\tbbox['y1'] = rows - y2\n",
        "\t\t\t\telif angle == 90:\n",
        "\t\t\t\t\tbbox['x1'] = rows - y2\n",
        "\t\t\t\t\tbbox['x2'] = rows - y1\n",
        "\t\t\t\t\tbbox['y1'] = x1\n",
        "\t\t\t\t\tbbox['y2'] = x2        \n",
        "\t\t\t\telif angle == 0:\n",
        "\t\t\t\t\tpass\n",
        "\n",
        "\timg_data_aug['width'] = img.shape[1]\n",
        "\timg_data_aug['height'] = img.shape[0]\n",
        "\treturn img_data_aug, img\n",
        "\n",
        "def get_anchor_gt(all_img_data, C, img_length_calc_function, mode='abc'):\n",
        "\n",
        "\twhile True:\n",
        "\n",
        "\t\tfor img_data in all_img_data:\n",
        "\t\t\ttry:\n",
        "\t\t\t\tif mode == 'train':\n",
        "\t\t\t\t\timg_data_aug, x_img = augment(img_data, C, augment=True)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\timg_data_aug, x_img = augment(img_data, C, augment=False)\n",
        "\n",
        "\t\t\t\t(width, height) = (img_data_aug['width'], img_data_aug['height'])\n",
        "\t\t\t\t(rows, cols, _) = x_img.shape\n",
        "\n",
        "\t\t\t\tassert cols == width\n",
        "\t\t\t\tassert rows == height\n",
        "\n",
        "\t\t\t\t(resized_width, resized_height) = get_new_img_size(width, height, C.im_size)\n",
        "\n",
        "\t\t\t\tx_img = cv2.resize(x_img, (resized_width, resized_height), interpolation=cv2.INTER_CUBIC)\n",
        "\t\t\t\tdebug_img = x_img.copy()\n",
        "\n",
        "\t\t\t\ttry:\n",
        "\t\t\t\t\ty_rpn_cls, y_rpn_regr, num_pos = calc_rpn(C, img_data_aug, width, height, resized_width, resized_height, img_length_calc_function)\n",
        "\t\t\t\texcept:\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\tx_img = x_img.astype(np.float32)\n",
        "\t\t\t\tx_img[:, :, 0] -= C.img_channel_mean[0]\n",
        "\t\t\t\tx_img[:, :, 1] -= C.img_channel_mean[1]\n",
        "\t\t\t\tx_img[:, :, 2] -= C.img_channel_mean[2]\n",
        "\t\t\t\tx_img /= C.img_scaling_factor\n",
        "\n",
        "\t\t\t\tx_img = np.transpose(x_img, (2, 0, 1))\n",
        "\t\t\t\tx_img = np.expand_dims(x_img, axis=0)\n",
        "\n",
        "\t\t\t\ty_rpn_regr[:, y_rpn_regr.shape[1]//2:, :, :] *= C.std_scaling\n",
        "\n",
        "\t\t\t\tx_img = np.transpose(x_img, (0, 2, 3, 1))\n",
        "\t\t\t\ty_rpn_cls = np.transpose(y_rpn_cls, (0, 2, 3, 1))\n",
        "\t\t\t\ty_rpn_regr = np.transpose(y_rpn_regr, (0, 2, 3, 1))\n",
        "\n",
        "\t\t\t\tyield np.copy(x_img), [np.copy(y_rpn_cls), np.copy(y_rpn_regr)], img_data_aug, debug_img, num_pos\n",
        "\n",
        "\t\t\texcept Exception as e:\n",
        "\t\t\t\tprint(e)\n",
        "\t\t\t\tcontinue\n",
        "\n",
        "def non_max_suppression_fast(boxes, probs, overlap_thresh=0.9, max_boxes=300):\n",
        "    if len(boxes) == 0:\n",
        "        return []\n",
        "\n",
        "    x1 = boxes[:, 0]\n",
        "    y1 = boxes[:, 1]\n",
        "    x2 = boxes[:, 2]\n",
        "    y2 = boxes[:, 3]\n",
        "\n",
        "    np.testing.assert_array_less(x1, x2)\n",
        "    np.testing.assert_array_less(y1, y2)\n",
        "\n",
        "    if boxes.dtype.kind == \"i\":\n",
        "        boxes = boxes.astype(\"float\")\n",
        "    pick = []\n",
        "    area = (x2 - x1) * (y2 - y1)\n",
        "    idxs = np.argsort(probs)\n",
        "    while len(idxs) > 0:\n",
        "        last = len(idxs) - 1\n",
        "        i = idxs[last]\n",
        "        pick.append(i)\n",
        "        xx1_int = np.maximum(x1[i], x1[idxs[:last]])\n",
        "        yy1_int = np.maximum(y1[i], y1[idxs[:last]])\n",
        "        xx2_int = np.minimum(x2[i], x2[idxs[:last]])\n",
        "        yy2_int = np.minimum(y2[i], y2[idxs[:last]])\n",
        "\n",
        "        ww_int = np.maximum(0, xx2_int - xx1_int)\n",
        "        hh_int = np.maximum(0, yy2_int - yy1_int)\n",
        "\n",
        "        area_int = ww_int * hh_int\n",
        "        area_union = area[i] + area[idxs[:last]] - area_int\n",
        "\n",
        "        overlap = area_int/(area_union + 1e-6)\n",
        "        idxs = np.delete(idxs, np.concatenate(([last],\n",
        "            np.where(overlap > overlap_thresh)[0])))\n",
        "\n",
        "        if len(pick) >= max_boxes:\n",
        "            break\n",
        "\n",
        "    boxes = boxes[pick].astype(\"int\")\n",
        "    probs = probs[pick]\n",
        "    return boxes, probs\n",
        "\n",
        "def apply_regr_np(X, T):\n",
        "    try:\n",
        "        x = X[0, :, :]\n",
        "        y = X[1, :, :]\n",
        "        w = X[2, :, :]\n",
        "        h = X[3, :, :]\n",
        "\n",
        "        tx = T[0, :, :]\n",
        "        ty = T[1, :, :]\n",
        "        tw = T[2, :, :]\n",
        "        th = T[3, :, :]\n",
        "\n",
        "        cx = x + w/2.\n",
        "        cy = y + h/2.\n",
        "        cx1 = tx * w + cx\n",
        "        cy1 = ty * h + cy\n",
        "\n",
        "        w1 = np.exp(tw.astype(np.float64)) * w\n",
        "        h1 = np.exp(th.astype(np.float64)) * h\n",
        "        x1 = cx1 - w1/2.\n",
        "        y1 = cy1 - h1/2.\n",
        "\n",
        "        x1 = np.round(x1)\n",
        "        y1 = np.round(y1)\n",
        "        w1 = np.round(w1)\n",
        "        h1 = np.round(h1)\n",
        "        return np.stack([x1, y1, w1, h1])\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        return X\n",
        "    \n",
        "def apply_regr(x, y, w, h, tx, ty, tw, th):\n",
        "    try:\n",
        "        cx = x + w/2.\n",
        "        cy = y + h/2.\n",
        "        cx1 = tx * w + cx\n",
        "        cy1 = ty * h + cy\n",
        "        w1 = math.exp(tw) * w\n",
        "        h1 = math.exp(th) * h\n",
        "        x1 = cx1 - w1/2.\n",
        "        y1 = cy1 - h1/2.\n",
        "        x1 = int(round(x1))\n",
        "        y1 = int(round(y1))\n",
        "        w1 = int(round(w1))\n",
        "        h1 = int(round(h1))\n",
        "\n",
        "        return x1, y1, w1, h1\n",
        "\n",
        "    except ValueError:\n",
        "        return x, y, w, h\n",
        "    except OverflowError:\n",
        "        return x, y, w, h\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        return x, y, w, h\n",
        "\n",
        "def calc_iou(R, img_data, C, class_mapping):\n",
        "    bboxes = img_data['bboxes']\n",
        "    (width, height) = (img_data['width'], img_data['height'])\n",
        "    (resized_width, resized_height) = get_new_img_size(width, height, C.im_size)\n",
        "\n",
        "    gta = np.zeros((len(bboxes), 4))\n",
        "\n",
        "    for bbox_num, bbox in enumerate(bboxes):\n",
        "        gta[bbox_num, 0] = int(round(bbox['x1'] * (resized_width / float(width))/C.rpn_stride))\n",
        "        gta[bbox_num, 1] = int(round(bbox['x2'] * (resized_width / float(width))/C.rpn_stride))\n",
        "        gta[bbox_num, 2] = int(round(bbox['y1'] * (resized_height / float(height))/C.rpn_stride))\n",
        "        gta[bbox_num, 3] = int(round(bbox['y2'] * (resized_height / float(height))/C.rpn_stride))\n",
        "\n",
        "    x_roi = []\n",
        "    y_class_num = []\n",
        "    y_class_regr_coords = []\n",
        "    y_class_regr_label = []\n",
        "    IoUs = []\n",
        "\n",
        "    for ix in range(R.shape[0]):\n",
        "        (x1, y1, x2, y2) = R[ix, :]\n",
        "        x1 = int(round(x1))\n",
        "        y1 = int(round(y1))\n",
        "        x2 = int(round(x2))\n",
        "        y2 = int(round(y2))\n",
        "\n",
        "        best_iou = 0.0\n",
        "        best_bbox = -1\n",
        "    \n",
        "        for bbox_num in range(len(bboxes)):\n",
        "            curr_iou = iou([gta[bbox_num, 0], gta[bbox_num, 2], gta[bbox_num, 1], gta[bbox_num, 3]], [x1, y1, x2, y2])\n",
        "\n",
        "            if curr_iou > best_iou:\n",
        "                best_iou = curr_iou\n",
        "                best_bbox = bbox_num\n",
        "\n",
        "        if best_iou < C.classifier_min_overlap:\n",
        "                continue\n",
        "        else:\n",
        "            w = x2 - x1\n",
        "            h = y2 - y1\n",
        "            x_roi.append([x1, y1, w, h])\n",
        "            IoUs.append(best_iou)\n",
        "\n",
        "            if C.classifier_min_overlap <= best_iou < C.classifier_max_overlap:\n",
        "                cls_name = 'bg'\n",
        "            elif C.classifier_max_overlap <= best_iou:\n",
        "                cls_name = bboxes[best_bbox]['class']\n",
        "                cxg = (gta[best_bbox, 0] + gta[best_bbox, 1]) / 2.0\n",
        "                cyg = (gta[best_bbox, 2] + gta[best_bbox, 3]) / 2.0\n",
        "\n",
        "                cx = x1 + w / 2.0\n",
        "                cy = y1 + h / 2.0\n",
        "\n",
        "                tx = (cxg - cx) / float(w)\n",
        "                ty = (cyg - cy) / float(h)\n",
        "                tw = np.log((gta[best_bbox, 1] - gta[best_bbox, 0]) / float(w))\n",
        "                th = np.log((gta[best_bbox, 3] - gta[best_bbox, 2]) / float(h))\n",
        "            else:\n",
        "                print('roi = {}'.format(best_iou))\n",
        "                raise RuntimeError\n",
        "\n",
        "        class_num = class_mapping[cls_name]\n",
        "        class_label = len(class_mapping) * [0]\n",
        "        class_label[class_num] = 1\n",
        "        y_class_num.append(copy.deepcopy(class_label))\n",
        "        coords = [0] * 4 * (len(class_mapping) - 1)\n",
        "        labels = [0] * 4 * (len(class_mapping) - 1)\n",
        "        if cls_name != 'bg':\n",
        "            label_pos = 4 * class_num\n",
        "            sx, sy, sw, sh = C.classifier_regr_std\n",
        "            coords[label_pos:4+label_pos] = [sx*tx, sy*ty, sw*tw, sh*th]\n",
        "            labels[label_pos:4+label_pos] = [1, 1, 1, 1]\n",
        "            y_class_regr_coords.append(copy.deepcopy(coords))\n",
        "            y_class_regr_label.append(copy.deepcopy(labels))\n",
        "        else:\n",
        "            y_class_regr_coords.append(copy.deepcopy(coords))\n",
        "            y_class_regr_label.append(copy.deepcopy(labels))\n",
        "\n",
        "    if len(x_roi) == 0:\n",
        "        return None, None, None, None\n",
        "\n",
        "    X = np.array(x_roi)\n",
        "    Y1 = np.array(y_class_num)\n",
        "    Y2 = np.concatenate([np.array(y_class_regr_label),np.array(y_class_regr_coords)],axis=1)\n",
        "\n",
        "    return np.expand_dims(X, axis=0), np.expand_dims(Y1, axis=0), np.expand_dims(Y2, axis=0), IoUs\n",
        "\n",
        "def rpn_to_roi(rpn_layer, regr_layer, C, dim_ordering, use_regr=True, max_boxes=300,overlap_thresh=0.9):\n",
        "\t\n",
        "\tregr_layer = regr_layer / C.std_scaling\n",
        "\n",
        "\tanchor_sizes = C.anchor_box_scales  \n",
        "\tanchor_ratios = C.anchor_box_ratios  \n",
        "\n",
        "\tassert rpn_layer.shape[0] == 1\n",
        "\n",
        "\t(rows, cols) = rpn_layer.shape[1:3]\n",
        "\n",
        "\tcurr_layer = 0\n",
        "\n",
        "\tA = np.zeros((4, rpn_layer.shape[1], rpn_layer.shape[2], rpn_layer.shape[3]))\n",
        "\n",
        "\tfor anchor_size in anchor_sizes:\n",
        "\t\tfor anchor_ratio in anchor_ratios:\n",
        "\t\t\tanchor_x = (anchor_size * anchor_ratio[0])/C.rpn_stride\n",
        "\t\t\tanchor_y = (anchor_size * anchor_ratio[1])/C.rpn_stride\n",
        "\n",
        "\t\t\tregr = regr_layer[0, :, :, 4 * curr_layer:4 * curr_layer + 4] \n",
        "\t\t\tregr = np.transpose(regr, (2, 0, 1)) \n",
        "\t\t\t\n",
        "\t\t\tX, Y = np.meshgrid(np.arange(cols),np. arange(rows))\n",
        "\t\t\tA[0, :, :, curr_layer] = X - anchor_x/2 \n",
        "\t\t\tA[1, :, :, curr_layer] = Y - anchor_y/2 \n",
        "\t\t\tA[2, :, :, curr_layer] = anchor_x       \n",
        "\t\t\tA[3, :, :, curr_layer] = anchor_y      \n",
        "\t\t\tif use_regr:\n",
        "\t\t\t\tA[:, :, :, curr_layer] = apply_regr_np(A[:, :, :, curr_layer], regr)\n",
        "\t\t\t\n",
        "\t\t\tA[2, :, :, curr_layer] = np.maximum(1, A[2, :, :, curr_layer])\n",
        "\t\t\tA[3, :, :, curr_layer] = np.maximum(1, A[3, :, :, curr_layer])\n",
        "\t\t\t\n",
        "\t\t\tA[2, :, :, curr_layer] += A[0, :, :, curr_layer]\n",
        "\t\t\tA[3, :, :, curr_layer] += A[1, :, :, curr_layer]\n",
        "\n",
        "\t\t\tA[0, :, :, curr_layer] = np.maximum(0, A[0, :, :, curr_layer])\n",
        "\t\t\tA[1, :, :, curr_layer] = np.maximum(0, A[1, :, :, curr_layer])\n",
        "\t\t\tA[2, :, :, curr_layer] = np.minimum(cols-1, A[2, :, :, curr_layer])\n",
        "\t\t\tA[3, :, :, curr_layer] = np.minimum(rows-1, A[3, :, :, curr_layer])\n",
        "\n",
        "\t\t\tcurr_layer += 1\n",
        "\n",
        "\tall_boxes = np.reshape(A.transpose((0, 3, 1, 2)), (4, -1)).transpose((1, 0))  \n",
        "\tall_probs = rpn_layer.transpose((0, 3, 1, 2)).reshape((-1))                  \n",
        "\n",
        "\tx1 = all_boxes[:, 0]\n",
        "\ty1 = all_boxes[:, 1]\n",
        "\tx2 = all_boxes[:, 2]\n",
        "\ty2 = all_boxes[:, 3]\n",
        "\n",
        "\tidxs = np.where((x1 - x2 >= 0) | (y1 - y2 >= 0))\n",
        "\n",
        "\tall_boxes = np.delete(all_boxes, idxs, 0)\n",
        "\tall_probs = np.delete(all_probs, idxs, 0)\n",
        "\n",
        "\tresult = non_max_suppression_fast(all_boxes, all_probs, overlap_thresh=overlap_thresh, max_boxes=max_boxes)[0]\n",
        "\n",
        "\treturn result\n",
        "\n",
        "lambda_rpn_regr = 1.0\n",
        "lambda_rpn_class = 1.0\n",
        "\n",
        "lambda_cls_regr = 1.0\n",
        "lambda_cls_class = 1.0\n",
        "\n",
        "epsilon = 1e-4\n",
        "\n",
        "def rpn_loss_regr(num_anchors):\n",
        "   \n",
        "    def rpn_loss_regr_fixed_num(y_true, y_pred):\n",
        "\n",
        "        x = y_true[:, :, :, 4 * num_anchors:] - y_pred\n",
        "        x_abs = K.abs(x)\n",
        "        x_bool = K.cast(K.less_equal(x_abs, 1.0), tf.float32)\n",
        "\n",
        "        return lambda_rpn_regr * K.sum(\n",
        "            y_true[:, :, :, :4 * num_anchors] * (x_bool * (0.5 * x * x) + (1 - x_bool) * (x_abs - 0.5))) / K.sum(epsilon + y_true[:, :, :, :4 * num_anchors])\n",
        "\n",
        "    return rpn_loss_regr_fixed_num\n",
        "\n",
        "\n",
        "def rpn_loss_cls(num_anchors):\n",
        "   \n",
        "    def rpn_loss_cls_fixed_num(y_true, y_pred):\n",
        "\n",
        "            return lambda_rpn_class * K.sum(y_true[:, :, :, :num_anchors] * K.binary_crossentropy(y_pred[:, :, :, :], y_true[:, :, :, num_anchors:])) / K.sum(epsilon + y_true[:, :, :, :num_anchors])\n",
        "\n",
        "    return rpn_loss_cls_fixed_num\n",
        "\n",
        "\n",
        "def class_loss_regr(num_classes):\n",
        "    \n",
        "    def class_loss_regr_fixed_num(y_true, y_pred):\n",
        "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
        "        x_abs = K.abs(x)\n",
        "        x_bool = K.cast(K.less_equal(x_abs, 1.0), 'float32')\n",
        "        return lambda_cls_regr * K.sum(y_true[:, :, :4*num_classes] * (x_bool * (0.5 * x * x) + (1 - x_bool) * (x_abs - 0.5))) / K.sum(epsilon + y_true[:, :, :4*num_classes])\n",
        "    return class_loss_regr_fixed_num\n",
        "\n",
        "\n",
        "def class_loss_cls(y_true, y_pred):\n",
        "    return lambda_cls_class * K.mean(categorical_crossentropy(y_true[0, :, :], y_pred[0, :, :]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJfk9dkEX9T5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RoiPoolingConv(Layer):\n",
        "    \n",
        "    def __init__(self, pool_size, num_rois, **kwargs):\n",
        "        self.pool_size = pool_size\n",
        "        self.num_rois = num_rois\n",
        "\n",
        "        super(RoiPoolingConv, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.nb_channels = input_shape[0][3]   \n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return None, self.num_rois, self.pool_size, self.pool_size, self.nb_channels\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "\n",
        "        assert(len(x) == 2)\n",
        "        img = x[0]\n",
        "        rois = x[1]\n",
        "        input_shape = K.shape(img)\n",
        "        outputs = []\n",
        "\n",
        "        for roi_idx in range(self.num_rois):\n",
        "\n",
        "            x = rois[0, roi_idx, 0]\n",
        "            y = rois[0, roi_idx, 1]\n",
        "            w = rois[0, roi_idx, 2]\n",
        "            h = rois[0, roi_idx, 3]\n",
        "\n",
        "            x = K.cast(x, 'int32')\n",
        "            y = K.cast(y, 'int32')\n",
        "            w = K.cast(w, 'int32')\n",
        "            h = K.cast(h, 'int32')\n",
        "\n",
        "            rs = tf.image.resize(img[:, y:y+h, x:x+w, :], (self.pool_size, self.pool_size))\n",
        "            outputs.append(rs)\n",
        "                \n",
        "\n",
        "        final_output = K.concatenate(outputs, axis=0)\n",
        "        final_output = K.reshape(final_output, (1, self.num_rois, self.pool_size, self.pool_size, self.nb_channels))\n",
        "        final_output = K.permute_dimensions(final_output, (0, 1, 2, 3, 4))\n",
        "\n",
        "        return final_output\n",
        "    \n",
        "    \n",
        "    def get_config(self):\n",
        "        config = {'pool_size': self.pool_size,\n",
        "                  'num_rois': self.num_rois}\n",
        "        base_config = super(RoiPoolingConv, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "def get_img_output_length(width, height):\n",
        "    def get_output_length(input_length):\n",
        "        return input_length//16\n",
        "\n",
        "    return get_output_length(width), get_output_length(height)    \n",
        "\n",
        "def nn_base(input_tensor=None, trainable=False):\n",
        "\n",
        "\n",
        "    input_shape = (None, None, 3)\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = Input(shape=input_shape)\n",
        "    else:\n",
        "        if not K.is_keras_tensor(input_tensor):\n",
        "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "\n",
        "    bn_axis = 3\n",
        "\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
        "\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
        "\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
        "\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
        "\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def rpn_layer(base_layers, num_anchors):\n",
        "    \n",
        "    x = Conv2D(512, (3, 3), padding='same', activation='relu', kernel_initializer='normal', name='rpn_conv1')(base_layers)\n",
        "\n",
        "    x_class = Conv2D(num_anchors, (1, 1), activation='sigmoid', kernel_initializer='uniform', name='rpn_out_class')(x)\n",
        "    x_regr = Conv2D(num_anchors * 4, (1, 1), activation='linear', kernel_initializer='zero', name='rpn_out_regress')(x)\n",
        "\n",
        "    return [x_class, x_regr, base_layers]\n",
        "\n",
        "def classifier_layer(base_layers, input_rois, num_rois, nb_classes = 4):\n",
        "   \n",
        "    input_shape = (num_rois,7,7,512)\n",
        "\n",
        "    pooling_regions = 7\n",
        "\n",
        "    out_roi_pool = RoiPoolingConv(pooling_regions, num_rois)([base_layers, input_rois])\n",
        "\n",
        "    out = TimeDistributed(Flatten(name='flatten'))(out_roi_pool)\n",
        "    out = TimeDistributed(Dense(4096, activation='relu', name='fc1'))(out)\n",
        "    out = TimeDistributed(Dropout(0.5))(out)\n",
        "    out = TimeDistributed(Dense(4096, activation='relu', name='fc2'))(out)\n",
        "    out = TimeDistributed(Dropout(0.5))(out)\n",
        "\n",
        "    out_class = TimeDistributed(Dense(nb_classes, activation='softmax', kernel_initializer='zero'), name='dense_class_{}'.format(nb_classes))(out)\n",
        "    out_regr = TimeDistributed(Dense(4 * (nb_classes-1), activation='linear', kernel_initializer='zero'), name='dense_regress_{}'.format(nb_classes))(out)\n",
        "\n",
        "    return [out_class, out_regr]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teUjNLeGYWMR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "ba1f97a4-040b-49ef-8fad-21342e3eab99"
      },
      "source": [
        "base_path = '/content/drive/My Drive/Colab Notebooks/'\n",
        "\n",
        "train_path =  '/content/drive/My Drive/Colab Notebooks/imgInfo.txt' \n",
        "\n",
        "num_rois = 4 \n",
        "\n",
        "\n",
        "horizontal_flips = True \n",
        "vertical_flips = True   \n",
        "rot_90 = True          \n",
        "\n",
        "output_weight_path = os.path.join(base_path, 'model/model_frcnn_vgg16.hdf5')\n",
        "\n",
        "record_path = os.path.join(base_path, 'model/record_vgg.csv') \n",
        "\n",
        "base_weight_path = os.path.join(base_path, 'model/vgg16_weights_tf_dim_ordering_tf_kernels.h5')\n",
        "\n",
        "config_output_filename = os.path.join(base_path, 'model_vgg_config.pickle')\n",
        "\n",
        "C = Config()\n",
        "\n",
        "C.use_horizontal_flips = horizontal_flips\n",
        "C.use_vertical_flips = vertical_flips\n",
        "C.rot_90 = rot_90\n",
        "\n",
        "C.record_path = record_path\n",
        "C.model_path = output_weight_path\n",
        "C.num_rois = num_rois\n",
        "\n",
        "C.base_net_weights = base_weight_path\n",
        "\n",
        "train_imgs, classes_count, class_mapping = get_data()\n",
        "\n",
        "if 'bg' not in classes_count:\n",
        "\tclasses_count['bg'] = 0\n",
        "\tclass_mapping['bg'] = len(class_mapping)\n",
        "\n",
        "C.class_mapping = class_mapping\n",
        "\n",
        "print('Training images per class:')\n",
        "pprint.pprint(classes_count)\n",
        "print('Num classes (including bg) = {}'.format(len(classes_count)))\n",
        "print(class_mapping)\n",
        "\n",
        "with open(config_output_filename, 'wb') as config_f:\n",
        "\tpickle.dump(C,config_f)\n",
        "\tprint('Config has been written to {}, and can be loaded when testing to ensure correct results'.format(config_output_filename))\n",
        "\n",
        "random.seed(1)\n",
        "random.shuffle(train_imgs)\n",
        "\n",
        "data_gen_train = get_anchor_gt(train_imgs, C, get_img_output_length, mode='train')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training images per class:\n",
            "{'Car': 1992,\n",
            " 'Cat': 812,\n",
            " 'Human face': 1863,\n",
            " 'Laptop': 1099,\n",
            " 'Mobile phone': 1062,\n",
            " 'Person': 2918,\n",
            " 'bg': 0}\n",
            "Num classes (including bg) = 7\n",
            "{'Person': 0, 'Car': 1, 'Human face': 2, 'Mobile phone': 3, 'Cat': 4, 'Laptop': 5, 'bg': 6}\n",
            "Config has been written to /content/drive/My Drive/Colab Notebooks/model_vgg_config.pickle, and can be loaded when testing to ensure correct results\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpkiLZmXYl9Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7457fbfe-6547-418b-eee6-5f87f68dee57"
      },
      "source": [
        "input_shape_img = (None, None, 3)\n",
        "\n",
        "img_input = Input(shape=input_shape_img)\n",
        "roi_input = Input(shape=(None, 4))\n",
        "\n",
        "\n",
        "shared_layers = nn_base(img_input, trainable=True)\n",
        "\n",
        "num_anchors = len(C.anchor_box_scales) * len(C.anchor_box_ratios) \n",
        "rpn = rpn_layer(shared_layers, num_anchors)\n",
        "\n",
        "classifier = classifier_layer(shared_layers, roi_input, C.num_rois, nb_classes=len(classes_count))\n",
        "\n",
        "model_rpn = Model(img_input, rpn[:2])\n",
        "model_classifier = Model([img_input, roi_input], classifier)\n",
        "\n",
        "\n",
        "model_all = Model([img_input, roi_input], rpn[:2] + classifier)\n",
        "\n",
        "if not os.path.isfile(C.model_path):\n",
        "    try:\n",
        "        print('This is the first time of your training')\n",
        "        print('loading weights from {}'.format(C.base_net_weights))\n",
        "        model_rpn.load_weights(C.base_net_weights, by_name=True)\n",
        "        model_classifier.load_weights(C.base_net_weights, by_name=True)\n",
        "        print('load weights success')\n",
        "    except:\n",
        "        print('Could not load pretrained model weights. Weights can be found in the keras application folder \\\n",
        "            https://github.com/fchollet/keras/tree/master/keras/applications')\n",
        "    \n",
        "    record_df = pd.DataFrame(columns=['mean_overlapping_bboxes', 'class_acc', 'loss_rpn_cls', 'loss_rpn_regr', 'loss_class_cls', 'loss_class_regr', 'curr_loss', 'elapsed_time', 'mAP'])\n",
        "else:\n",
        "    \n",
        "    print('Continue training based on previous trained model')\n",
        "    print('Loading weights from {}'.format(C.model_path))\n",
        "    model_rpn.load_weights(C.model_path, by_name=True)\n",
        "    model_classifier.load_weights(C.model_path, by_name=True)\n",
        "    \n",
        "    record_df = pd.read_csv(record_path)\n",
        "\n",
        "    r_mean_overlapping_bboxes = record_df['mean_overlapping_bboxes']\n",
        "    r_class_acc = record_df['class_acc']\n",
        "    r_loss_rpn_cls = record_df['loss_rpn_cls']\n",
        "    r_loss_rpn_regr = record_df['loss_rpn_regr']\n",
        "    r_loss_class_cls = record_df['loss_class_cls']\n",
        "    r_loss_class_regr = record_df['loss_class_regr']\n",
        "    r_curr_loss = record_df['curr_loss']\n",
        "    r_elapsed_time = record_df['elapsed_time']\n",
        "    r_mAP = record_df['mAP']\n",
        "\n",
        "    print('Already train %dK batches'% (len(record_df)))\n",
        "\n",
        "optimizer = Adam(lr=1e-5)\n",
        "optimizer_classifier = Adam(lr=1e-5)\n",
        "model_rpn.compile(optimizer=optimizer, loss=[rpn_loss_cls(num_anchors), rpn_loss_regr(num_anchors)])\n",
        "model_classifier.compile(optimizer=optimizer_classifier, loss=[class_loss_cls, class_loss_regr(len(classes_count)-1)], metrics={'dense_class_{}'.format(len(classes_count)): 'accuracy'})\n",
        "model_all.compile(optimizer='sgd', loss='mae')\n",
        "\n",
        "total_epochs = len(record_df)\n",
        "r_epochs = len(record_df)\n",
        "\n",
        "epoch_length = 1000\n",
        "num_epochs = 40\n",
        "iter_num = 0\n",
        "\n",
        "total_epochs += num_epochs\n",
        "\n",
        "losses = np.zeros((epoch_length, 5))\n",
        "rpn_accuracy_rpn_monitor = []\n",
        "rpn_accuracy_for_epoch = []\n",
        "\n",
        "if len(record_df)==0:\n",
        "    best_loss = np.Inf\n",
        "else:\n",
        "    best_loss = np.min(r_curr_loss)\n",
        "\n",
        "start_time = time.time()\n",
        "for epoch_num in range(num_epochs):\n",
        "\n",
        "    progbar = generic_utils.Progbar(epoch_length)\n",
        "    print('Epoch {}/{}'.format(r_epochs + 1, total_epochs))\n",
        "    \n",
        "    r_epochs += 1\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "\n",
        "            if len(rpn_accuracy_rpn_monitor) == epoch_length and C.verbose:\n",
        "                mean_overlapping_bboxes = float(sum(rpn_accuracy_rpn_monitor))/len(rpn_accuracy_rpn_monitor)\n",
        "                rpn_accuracy_rpn_monitor = []\n",
        "                 \n",
        "                if mean_overlapping_bboxes == 0:\n",
        "                    print('RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.')\n",
        "\n",
        "            \n",
        "            X, Y, img_data, debug_img, debug_num_pos = next(data_gen_train)\n",
        "            loss_rpn = model_rpn.train_on_batch(X, Y)\n",
        "            P_rpn = model_rpn.predict_on_batch(X)\n",
        "            R = rpn_to_roi(P_rpn[0], P_rpn[1], C, None, use_regr=True, overlap_thresh=0.7, max_boxes=300)\n",
        "            \n",
        "            X2, Y1, Y2, IouS = calc_iou(R, img_data, C, class_mapping)\n",
        "\n",
        "            if X2 is None:\n",
        "                rpn_accuracy_rpn_monitor.append(0)\n",
        "                rpn_accuracy_for_epoch.append(0)\n",
        "                continue\n",
        "            \n",
        "            neg_samples = np.where(Y1[0, :, -1] == 1)\n",
        "            pos_samples = np.where(Y1[0, :, -1] == 0)\n",
        "\n",
        "            if len(neg_samples) > 0:\n",
        "                neg_samples = neg_samples[0]\n",
        "            else:\n",
        "                neg_samples = []\n",
        "\n",
        "            if len(pos_samples) > 0:\n",
        "                pos_samples = pos_samples[0]\n",
        "            else:\n",
        "                pos_samples = []\n",
        "\n",
        "            rpn_accuracy_rpn_monitor.append(len(pos_samples))\n",
        "            rpn_accuracy_for_epoch.append((len(pos_samples)))\n",
        "\n",
        "            if C.num_rois > 1:\n",
        "                if len(pos_samples) < C.num_rois//2:\n",
        "                    selected_pos_samples = pos_samples.tolist()\n",
        "                else:\n",
        "                    selected_pos_samples = np.random.choice(pos_samples, C.num_rois//2, replace=False).tolist()\n",
        "                \n",
        "                try:\n",
        "                    selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=False).tolist()\n",
        "                except:\n",
        "                    selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=True).tolist()\n",
        "                \n",
        "                sel_samples = selected_pos_samples + selected_neg_samples\n",
        "            else:\n",
        "                selected_pos_samples = pos_samples.tolist()\n",
        "                selected_neg_samples = neg_samples.tolist()\n",
        "                if np.random.randint(0, 2):\n",
        "                    sel_samples = random.choice(neg_samples)\n",
        "                else:\n",
        "                    sel_samples = random.choice(pos_samples)\n",
        "\n",
        "            loss_class = model_classifier.train_on_batch([X, X2[:, sel_samples, :]], [Y1[:, sel_samples, :], Y2[:, sel_samples, :]])\n",
        "\n",
        "            losses[iter_num, 0] = loss_rpn[1]\n",
        "            losses[iter_num, 1] = loss_rpn[2]\n",
        "\n",
        "            losses[iter_num, 2] = loss_class[1]\n",
        "            losses[iter_num, 3] = loss_class[2]\n",
        "            losses[iter_num, 4] = loss_class[3]\n",
        "\n",
        "            iter_num += 1\n",
        "\n",
        "            progbar.update(iter_num, [('rpn_cls', np.mean(losses[:iter_num, 0])), ('rpn_regr', np.mean(losses[:iter_num, 1])),\n",
        "                                      ('final_cls', np.mean(losses[:iter_num, 2])), ('final_regr', np.mean(losses[:iter_num, 3]))])\n",
        "\n",
        "            if iter_num == epoch_length:\n",
        "                loss_rpn_cls = np.mean(losses[:, 0])\n",
        "                loss_rpn_regr = np.mean(losses[:, 1])\n",
        "                loss_class_cls = np.mean(losses[:, 2])\n",
        "                loss_class_regr = np.mean(losses[:, 3])\n",
        "                class_acc = np.mean(losses[:, 4])\n",
        "\n",
        "                mean_overlapping_bboxes = float(sum(rpn_accuracy_for_epoch)) / len(rpn_accuracy_for_epoch)\n",
        "                rpn_accuracy_for_epoch = []\n",
        "\n",
        "                if C.verbose:\n",
        "                    print('Mean number of bounding boxes from RPN overlapping ground truth boxes: {}'.format(mean_overlapping_bboxes))\n",
        "                    print('Classifier accuracy for bounding boxes from RPN: {}'.format(class_acc))\n",
        "                    print('Loss RPN classifier: {}'.format(loss_rpn_cls))\n",
        "                    print('Loss RPN regression: {}'.format(loss_rpn_regr))\n",
        "                    print('Loss Detector classifier: {}'.format(loss_class_cls))\n",
        "                    print('Loss Detector regression: {}'.format(loss_class_regr))\n",
        "                    print('Total loss: {}'.format(loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr))\n",
        "                    print('Elapsed time: {}'.format(time.time() - start_time))\n",
        "                    elapsed_time = (time.time()-start_time)/60\n",
        "\n",
        "                curr_loss = loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr\n",
        "                iter_num = 0\n",
        "                start_time = time.time()\n",
        "\n",
        "                if curr_loss < best_loss:\n",
        "                    if C.verbose:\n",
        "                        print('Total loss decreased from {} to {}, saving weights'.format(best_loss,curr_loss))\n",
        "                    best_loss = curr_loss\n",
        "                    model_all.save_weights(C.model_path)\n",
        "\n",
        "                new_row = {'mean_overlapping_bboxes':round(mean_overlapping_bboxes, 3), \n",
        "                           'class_acc':round(class_acc, 3), \n",
        "                           'loss_rpn_cls':round(loss_rpn_cls, 3), \n",
        "                           'loss_rpn_regr':round(loss_rpn_regr, 3), \n",
        "                           'loss_class_cls':round(loss_class_cls, 3), \n",
        "                           'loss_class_regr':round(loss_class_regr, 3), \n",
        "                           'curr_loss':round(curr_loss, 3), \n",
        "                           'elapsed_time':round(elapsed_time, 3), \n",
        "                           'mAP': 0}\n",
        "\n",
        "                record_df = record_df.append(new_row, ignore_index=True)\n",
        "                record_df.to_csv(record_path, index=0)\n",
        "\n",
        "                break\n",
        "        except Exception as e:\n",
        "            print('Exception: {}'.format(e))\n",
        "            continue\n",
        "        \n",
        "\n",
        "print('Training complete, exiting.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is the first time of your training\n",
            "loading weights from /content/drive/My Drive/Colab Notebooks/model/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "load weights success\n",
            "Epoch 1/40\n",
            "1000/1000 [==============================] - 645s 645ms/step - rpn_cls: 5.5073 - rpn_regr: 0.3907 - final_cls: 1.4181 - final_regr: 0.4098\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 7.072134387351778\n",
            "Classifier accuracy for bounding boxes from RPN: 0.59225\n",
            "Loss RPN classifier: 4.509834350704263\n",
            "Loss RPN regression: 0.38208806432783604\n",
            "Loss Detector classifier: 1.2921165596172213\n",
            "Loss Detector regression: 0.42700071617076174\n",
            "Total loss: 6.611039690820081\n",
            "Elapsed time: 644.5053749084473\n",
            "Total loss decreased from inf to 6.611039690820081, saving weights\n",
            "Epoch 2/40\n",
            "1000/1000 [==============================] - 562s 562ms/step - rpn_cls: 2.9894 - rpn_regr: 0.3555 - final_cls: 1.0488 - final_regr: 0.4390\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 8.109452736318408\n",
            "Classifier accuracy for bounding boxes from RPN: 0.612\n",
            "Loss RPN classifier: 2.954640078104684\n",
            "Loss RPN regression: 0.34401640061521904\n",
            "Loss Detector classifier: 1.0063932012170553\n",
            "Loss Detector regression: 0.4302189176231623\n",
            "Total loss: 4.735268597560121\n",
            "Elapsed time: 564.4688067436218\n",
            "Total loss decreased from 6.611039690820081 to 4.735268597560121, saving weights\n",
            "Epoch 3/40\n",
            "1000/1000 [==============================] - 553s 553ms/step - rpn_cls: 2.4653 - rpn_regr: 0.3435 - final_cls: 0.9066 - final_regr: 0.4046\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 8.208333333333334\n",
            "Classifier accuracy for bounding boxes from RPN: 0.64725\n",
            "Loss RPN classifier: 2.520796910736767\n",
            "Loss RPN regression: 0.3477841949025169\n",
            "Loss Detector classifier: 0.8810373458936811\n",
            "Loss Detector regression: 0.40649225920438764\n",
            "Total loss: 4.1561107107373525\n",
            "Elapsed time: 555.3608605861664\n",
            "Total loss decreased from 4.735268597560121 to 4.1561107107373525, saving weights\n",
            "Epoch 4/40\n",
            "1000/1000 [==============================] - 545s 545ms/step - rpn_cls: 2.5272 - rpn_regr: 0.3094 - final_cls: 0.8413 - final_regr: 0.3844\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 8.63010967098704\n",
            "Classifier accuracy for bounding boxes from RPN: 0.66075\n",
            "Loss RPN classifier: 2.5086120358943353\n",
            "Loss RPN regression: 0.30617982917046177\n",
            "Loss Detector classifier: 0.8366451583690941\n",
            "Loss Detector regression: 0.3934425138644874\n",
            "Total loss: 4.044879537298379\n",
            "Elapsed time: 547.5439229011536\n",
            "Total loss decreased from 4.1561107107373525 to 4.044879537298379, saving weights\n",
            "Epoch 5/40\n",
            " 275/1000 [=======>......................] - ETA: 3:55 - rpn_cls: 2.4005 - rpn_regr: 0.2583 - final_cls: 0.8309 - final_regr: 0.3752Exception: 'a' cannot be empty unless no samples are taken\n",
            "1000/1000 [==============================] - 279s 279ms/step - rpn_cls: 2.3120 - rpn_regr: 0.2977 - final_cls: 0.8252 - final_regr: 0.3745\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 9.194444444444445\n",
            "Classifier accuracy for bounding boxes from RPN: 0.674\n",
            "Loss RPN classifier: 2.286283667117475\n",
            "Loss RPN regression: 0.31578222986939364\n",
            "Loss Detector classifier: 0.8164368733726441\n",
            "Loss Detector regression: 0.3736632286151871\n",
            "Total loss: 3.7921659989747\n",
            "Elapsed time: 282.11503171920776\n",
            "Total loss decreased from 4.044879537298379 to 3.7921659989747, saving weights\n",
            "Epoch 6/40\n",
            "1000/1000 [==============================] - 258s 258ms/step - rpn_cls: 1.9968 - rpn_regr: 0.2794 - final_cls: 0.7542 - final_regr: 0.3749\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 9.409542743538767\n",
            "Classifier accuracy for bounding boxes from RPN: 0.69625\n",
            "Loss RPN classifier: 2.062714211188513\n",
            "Loss RPN regression: 0.28707484671799466\n",
            "Loss Detector classifier: 0.7719211032241583\n",
            "Loss Detector regression: 0.3718619416095316\n",
            "Total loss: 3.4935721027401976\n",
            "Elapsed time: 262.0179054737091\n",
            "Total loss decreased from 3.7921659989747 to 3.4935721027401976, saving weights\n",
            "Epoch 7/40\n",
            "1000/1000 [==============================] - 265s 265ms/step - rpn_cls: 1.9943 - rpn_regr: 0.3063 - final_cls: 0.8053 - final_regr: 0.3573\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 9.396620278330019\n",
            "Classifier accuracy for bounding boxes from RPN: 0.69475\n",
            "Loss RPN classifier: 2.057786656938133\n",
            "Loss RPN regression: 0.3109049079604447\n",
            "Loss Detector classifier: 0.7738823513761163\n",
            "Loss Detector regression: 0.3488717373497784\n",
            "Total loss: 3.4914456536244725\n",
            "Elapsed time: 268.0473618507385\n",
            "Total loss decreased from 3.4935721027401976 to 3.4914456536244725, saving weights\n",
            "Epoch 8/40\n",
            "1000/1000 [==============================] - 261s 261ms/step - rpn_cls: 2.1285 - rpn_regr: 0.2849 - final_cls: 0.7706 - final_regr: 0.3596\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 9.385842472582253\n",
            "Classifier accuracy for bounding boxes from RPN: 0.6825\n",
            "Loss RPN classifier: 1.9850312835522772\n",
            "Loss RPN regression: 0.2802167564732954\n",
            "Loss Detector classifier: 0.7744030395289883\n",
            "Loss Detector regression: 0.35993318419437853\n",
            "Total loss: 3.39958426374894\n",
            "Elapsed time: 263.92154240608215\n",
            "Total loss decreased from 3.4914456536244725 to 3.39958426374894, saving weights\n",
            "Epoch 9/40\n",
            "1000/1000 [==============================] - 259s 259ms/step - rpn_cls: 1.8686 - rpn_regr: 0.2900 - final_cls: 0.7377 - final_regr: 0.3341\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 9.734653465346534\n",
            "Classifier accuracy for bounding boxes from RPN: 0.70925\n",
            "Loss RPN classifier: 1.8434670753107683\n",
            "Loss RPN regression: 0.29026578711545153\n",
            "Loss Detector classifier: 0.7267482057996094\n",
            "Loss Detector regression: 0.3372385293878615\n",
            "Total loss: 3.197719597613691\n",
            "Elapsed time: 261.2586705684662\n",
            "Total loss decreased from 3.39958426374894 to 3.197719597613691, saving weights\n",
            "Epoch 10/40\n",
            "1000/1000 [==============================] - 257s 257ms/step - rpn_cls: 1.9320 - rpn_regr: 0.2831 - final_cls: 0.7018 - final_regr: 0.3335\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 9.895418326693227\n",
            "Classifier accuracy for bounding boxes from RPN: 0.70425\n",
            "Loss RPN classifier: 1.786353143310702\n",
            "Loss RPN regression: 0.27386694151023405\n",
            "Loss Detector classifier: 0.7147997063603252\n",
            "Loss Detector regression: 0.33878626983053983\n",
            "Total loss: 3.1138060610118012\n",
            "Elapsed time: 260.63204169273376\n",
            "Total loss decreased from 3.197719597613691 to 3.1138060610118012, saving weights\n",
            "Epoch 11/40\n",
            "1000/1000 [==============================] - 258s 258ms/step - rpn_cls: 1.7857 - rpn_regr: 0.2910 - final_cls: 0.6921 - final_regr: 0.3350\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 9.56175298804781\n",
            "Classifier accuracy for bounding boxes from RPN: 0.72725\n",
            "Loss RPN classifier: 1.7384172821944677\n",
            "Loss RPN regression: 0.29420238398388027\n",
            "Loss Detector classifier: 0.6721198049858212\n",
            "Loss Detector regression: 0.3335271694827825\n",
            "Total loss: 3.0382666406469516\n",
            "Elapsed time: 260.70371413230896\n",
            "Total loss decreased from 3.1138060610118012 to 3.0382666406469516, saving weights\n",
            "Epoch 12/40\n",
            "1000/1000 [==============================] - 259s 259ms/step - rpn_cls: 1.6841 - rpn_regr: 0.2648 - final_cls: 0.7327 - final_regr: 0.3191\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 9.795634920634921\n",
            "Classifier accuracy for bounding boxes from RPN: 0.71525\n",
            "Loss RPN classifier: 1.6848008182007037\n",
            "Loss RPN regression: 0.263735747192055\n",
            "Loss Detector classifier: 0.7089678565151989\n",
            "Loss Detector regression: 0.32394627374224366\n",
            "Total loss: 2.9814506956502016\n",
            "Elapsed time: 261.57271242141724\n",
            "Total loss decreased from 3.0382666406469516 to 2.9814506956502016, saving weights\n",
            "Epoch 13/40\n",
            "1000/1000 [==============================] - 259s 259ms/step - rpn_cls: 1.6714 - rpn_regr: 0.2649 - final_cls: 0.7024 - final_regr: 0.3250\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 10.071428571428571\n",
            "Classifier accuracy for bounding boxes from RPN: 0.72975\n",
            "Loss RPN classifier: 1.8034184206639188\n",
            "Loss RPN regression: 0.2787022658421192\n",
            "Loss Detector classifier: 0.6894245881149546\n",
            "Loss Detector regression: 0.3259744357634336\n",
            "Total loss: 3.097519710384426\n",
            "Elapsed time: 261.8962068557739\n",
            "Epoch 14/40\n",
            "1000/1000 [==============================] - 251s 251ms/step - rpn_cls: 1.6331 - rpn_regr: 0.2540 - final_cls: 0.6610 - final_regr: 0.3217\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 10.119047619047619\n",
            "Classifier accuracy for bounding boxes from RPN: 0.72675\n",
            "Loss RPN classifier: 1.5695266471005915\n",
            "Loss RPN regression: 0.24847526098694653\n",
            "Loss Detector classifier: 0.6604900096380152\n",
            "Loss Detector regression: 0.3262810659967363\n",
            "Total loss: 2.8047729837222897\n",
            "Elapsed time: 251.18871569633484\n",
            "Total loss decreased from 2.9814506956502016 to 2.8047729837222897, saving weights\n",
            "Epoch 15/40\n",
            "1000/1000 [==============================] - 259s 259ms/step - rpn_cls: 1.6303 - rpn_regr: 0.2837 - final_cls: 0.6509 - final_regr: 0.3187\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 9.99003984063745\n",
            "Classifier accuracy for bounding boxes from RPN: 0.73175\n",
            "Loss RPN classifier: 1.5573671545096885\n",
            "Loss RPN regression: 0.28355177407863086\n",
            "Loss Detector classifier: 0.6589173217713833\n",
            "Loss Detector regression: 0.3193775987876579\n",
            "Total loss: 2.819213849147361\n",
            "Elapsed time: 261.28032326698303\n",
            "Epoch 16/40\n",
            "1000/1000 [==============================] - 256s 256ms/step - rpn_cls: 1.6712 - rpn_regr: 0.2562 - final_cls: 0.6761 - final_regr: 0.3238\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 9.823061630218687\n",
            "Classifier accuracy for bounding boxes from RPN: 0.74125\n",
            "Loss RPN classifier: 1.6693479926948893\n",
            "Loss RPN regression: 0.2531190849424456\n",
            "Loss Detector classifier: 0.6618212307589129\n",
            "Loss Detector regression: 0.32813054258935154\n",
            "Total loss: 2.9124188509855995\n",
            "Elapsed time: 256.4295094013214\n",
            "Epoch 17/40\n",
            "1000/1000 [==============================] - 256s 256ms/step - rpn_cls: 1.5788 - rpn_regr: 0.2583 - final_cls: 0.6575 - final_regr: 0.3273\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 10.126858275520318\n",
            "Classifier accuracy for bounding boxes from RPN: 0.73275\n",
            "Loss RPN classifier: 1.6189763172995988\n",
            "Loss RPN regression: 0.26448230625805447\n",
            "Loss Detector classifier: 0.6516781143425032\n",
            "Loss Detector regression: 0.3184219155767933\n",
            "Total loss: 2.85355865347695\n",
            "Elapsed time: 256.0718297958374\n",
            "Epoch 18/40\n",
            "1000/1000 [==============================] - 253s 253ms/step - rpn_cls: 1.5260 - rpn_regr: 0.2552 - final_cls: 0.6230 - final_regr: 0.3034\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 10.168494516450648\n",
            "Classifier accuracy for bounding boxes from RPN: 0.739\n",
            "Loss RPN classifier: 1.4813007678750092\n",
            "Loss RPN regression: 0.2501521835285239\n",
            "Loss Detector classifier: 0.6386842150217853\n",
            "Loss Detector regression: 0.3134378274921328\n",
            "Total loss: 2.6835749939174516\n",
            "Elapsed time: 253.4820213317871\n",
            "Total loss decreased from 2.8047729837222897 to 2.6835749939174516, saving weights\n",
            "Epoch 19/40\n",
            " 190/1000 [====>.........................] - ETA: 3:29 - rpn_cls: 1.5816 - rpn_regr: 0.1996 - final_cls: 0.7000 - final_regr: 0.3135Exception: 'a' cannot be empty unless no samples are taken\n",
            "1000/1000 [==============================] - 259s 259ms/step - rpn_cls: 1.4926 - rpn_regr: 0.2514 - final_cls: 0.6574 - final_regr: 0.3204\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 9.828685258964143\n",
            "Classifier accuracy for bounding boxes from RPN: 0.74675\n",
            "Loss RPN classifier: 1.4675338637851774\n",
            "Loss RPN regression: 0.269589182801079\n",
            "Loss Detector classifier: 0.6364276888854802\n",
            "Loss Detector regression: 0.3172855001240969\n",
            "Total loss: 2.6908362355958335\n",
            "Elapsed time: 261.98725843429565\n",
            "Epoch 20/40\n",
            "1000/1000 [==============================] - 257s 257ms/step - rpn_cls: 1.6715 - rpn_regr: 0.2768 - final_cls: 0.6556 - final_regr: 0.2997\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 9.985059760956176\n",
            "Classifier accuracy for bounding boxes from RPN: 0.74075\n",
            "Loss RPN classifier: 1.5855710604540314\n",
            "Loss RPN regression: 0.2566698727142066\n",
            "Loss Detector classifier: 0.644712573165074\n",
            "Loss Detector regression: 0.3103229905855842\n",
            "Total loss: 2.7972764969188963\n",
            "Elapsed time: 256.8229036331177\n",
            "Epoch 21/40\n",
            "1000/1000 [==============================] - 260s 260ms/step - rpn_cls: 1.5522 - rpn_regr: 0.2672 - final_cls: 0.6695 - final_regr: 0.3103\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 10.097415506958251\n",
            "Classifier accuracy for bounding boxes from RPN: 0.73825\n",
            "Loss RPN classifier: 1.5988982303910937\n",
            "Loss RPN regression: 0.2652721360230353\n",
            "Loss Detector classifier: 0.643917965957895\n",
            "Loss Detector regression: 0.2904079622430727\n",
            "Total loss: 2.798496294615097\n",
            "Elapsed time: 260.19897198677063\n",
            "Epoch 22/40\n",
            "1000/1000 [==============================] - 258s 258ms/step - rpn_cls: 1.4961 - rpn_regr: 0.2549 - final_cls: 0.6113 - final_regr: 0.3060\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 10.66865671641791\n",
            "Classifier accuracy for bounding boxes from RPN: 0.755\n",
            "Loss RPN classifier: 1.4297833056789846\n",
            "Loss RPN regression: 0.2520651847834233\n",
            "Loss Detector classifier: 0.6163258250604849\n",
            "Loss Detector regression: 0.30162591420672835\n",
            "Total loss: 2.599800229729621\n",
            "Elapsed time: 257.7982008457184\n",
            "Total loss decreased from 2.6835749939174516 to 2.599800229729621, saving weights\n",
            "Epoch 23/40\n",
            "1000/1000 [==============================] - 259s 259ms/step - rpn_cls: 1.4418 - rpn_regr: 0.2438 - final_cls: 0.6406 - final_regr: 0.2987\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 10.061691542288557\n",
            "Classifier accuracy for bounding boxes from RPN: 0.7475\n",
            "Loss RPN classifier: 1.362127952905762\n",
            "Loss RPN regression: 0.25857594177266585\n",
            "Loss Detector classifier: 0.6190752003522357\n",
            "Loss Detector regression: 0.2963092835526913\n",
            "Total loss: 2.5360883785833552\n",
            "Elapsed time: 262.0350384712219\n",
            "Total loss decreased from 2.599800229729621 to 2.5360883785833552, saving weights\n",
            "Epoch 24/40\n",
            " 222/1000 [=====>........................] - ETA: 3:27 - rpn_cls: 1.7962 - rpn_regr: 0.2646 - final_cls: 0.5903 - final_regr: 0.3176Exception: 'a' cannot be empty unless no samples are taken\n",
            "1000/1000 [==============================] - 258s 258ms/step - rpn_cls: 1.6144 - rpn_regr: 0.2580 - final_cls: 0.6134 - final_regr: 0.3126\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 9.985074626865671\n",
            "Classifier accuracy for bounding boxes from RPN: 0.749\n",
            "Loss RPN classifier: 1.5187096571957404\n",
            "Loss RPN regression: 0.24682006183452904\n",
            "Loss Detector classifier: 0.6209503655945883\n",
            "Loss Detector regression: 0.30655031066108496\n",
            "Total loss: 2.693030395285943\n",
            "Elapsed time: 260.9802689552307\n",
            "Epoch 25/40\n",
            "1000/1000 [==============================] - 256s 256ms/step - rpn_cls: 1.5687 - rpn_regr: 0.2515 - final_cls: 0.6316 - final_regr: 0.3004\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 9.954319761668321\n",
            "Classifier accuracy for bounding boxes from RPN: 0.74175\n",
            "Loss RPN classifier: 1.5608569875582916\n",
            "Loss RPN regression: 0.2606181238379795\n",
            "Loss Detector classifier: 0.6356700732028112\n",
            "Loss Detector regression: 0.29209290448203684\n",
            "Total loss: 2.7492380890811194\n",
            "Elapsed time: 256.10336089134216\n",
            "Epoch 26/40\n",
            "1000/1000 [==============================] - 254s 254ms/step - rpn_cls: 1.4337 - rpn_regr: 0.2453 - final_cls: 0.5971 - final_regr: 0.2863\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 10.347609561752988\n",
            "Classifier accuracy for bounding boxes from RPN: 0.75425\n",
            "Loss RPN classifier: 1.3592818467461065\n",
            "Loss RPN regression: 0.24549894349789247\n",
            "Loss Detector classifier: 0.6010000622216612\n",
            "Loss Detector regression: 0.28742298217047935\n",
            "Total loss: 2.4932038346361396\n",
            "Elapsed time: 253.62375450134277\n",
            "Total loss decreased from 2.5360883785833552 to 2.4932038346361396, saving weights\n",
            "Epoch 27/40\n",
            "1000/1000 [==============================] - 258s 258ms/step - rpn_cls: 1.3148 - rpn_regr: 0.2433 - final_cls: 0.6336 - final_regr: 0.2977\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 10.312437810945273\n",
            "Classifier accuracy for bounding boxes from RPN: 0.74775\n",
            "Loss RPN classifier: 1.2846422002229052\n",
            "Loss RPN regression: 0.25819497151486576\n",
            "Loss Detector classifier: 0.6148898105663247\n",
            "Loss Detector regression: 0.28232034779991955\n",
            "Total loss: 2.440047330104015\n",
            "Elapsed time: 260.83511185646057\n",
            "Total loss decreased from 2.4932038346361396 to 2.440047330104015, saving weights\n",
            "Epoch 28/40\n",
            " 288/1000 [=======>......................] - ETA: 3:07 - rpn_cls: 1.3838 - rpn_regr: 0.2305 - final_cls: 0.5936 - final_regr: 0.2700Exception: 'a' cannot be empty unless no samples are taken\n",
            "1000/1000 [==============================] - 258s 258ms/step - rpn_cls: 1.3892 - rpn_regr: 0.2478 - final_cls: 0.6143 - final_regr: 0.2818\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 10.165503489531405\n",
            "Classifier accuracy for bounding boxes from RPN: 0.74725\n",
            "Loss RPN classifier: 1.3656909658250072\n",
            "Loss RPN regression: 0.2456003098669462\n",
            "Loss Detector classifier: 0.6263504982860759\n",
            "Loss Detector regression: 0.289533637214452\n",
            "Total loss: 2.527175411192481\n",
            "Elapsed time: 260.86935591697693\n",
            "Epoch 29/40\n",
            "1000/1000 [==============================] - 257s 257ms/step - rpn_cls: 1.3964 - rpn_regr: 0.2472 - final_cls: 0.6194 - final_regr: 0.2934\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 10.343283582089553\n",
            "Classifier accuracy for bounding boxes from RPN: 0.75125\n",
            "Loss RPN classifier: 1.47503280881612\n",
            "Loss RPN regression: 0.25445537341118324\n",
            "Loss Detector classifier: 0.6088334555502515\n",
            "Loss Detector regression: 0.294975730442442\n",
            "Total loss: 2.633297368219997\n",
            "Elapsed time: 257.2052707672119\n",
            "Epoch 30/40\n",
            "1000/1000 [==============================] - 257s 257ms/step - rpn_cls: 1.3446 - rpn_regr: 0.2436 - final_cls: 0.6051 - final_regr: 0.2861\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 10.875498007968128\n",
            "Classifier accuracy for bounding boxes from RPN: 0.74625\n",
            "Loss RPN classifier: 1.393830062900637\n",
            "Loss RPN regression: 0.2384404546932201\n",
            "Loss Detector classifier: 0.6054613788698334\n",
            "Loss Detector regression: 0.28189869883377106\n",
            "Total loss: 2.5196305952974614\n",
            "Elapsed time: 256.5603783130646\n",
            "Epoch 31/40\n",
            "1000/1000 [==============================] - 256s 256ms/step - rpn_cls: 1.3474 - rpn_regr: 0.2394 - final_cls: 0.6079 - final_regr: 0.3001\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 10.439121756487026\n",
            "Classifier accuracy for bounding boxes from RPN: 0.759\n",
            "Loss RPN classifier: 1.3127485618627621\n",
            "Loss RPN regression: 0.24619678743742407\n",
            "Loss Detector classifier: 0.592496126784943\n",
            "Loss Detector regression: 0.2908746264958754\n",
            "Total loss: 2.4423161025810045\n",
            "Elapsed time: 255.63589024543762\n",
            "Epoch 32/40\n",
            " 360/1000 [=========>....................] - ETA: 2:48 - rpn_cls: 1.4380 - rpn_regr: 0.2618 - final_cls: 0.5578 - final_regr: 0.3023Exception: 'a' cannot be empty unless no samples are taken\n",
            "1000/1000 [==============================] - 259s 259ms/step - rpn_cls: 1.4136 - rpn_regr: 0.2540 - final_cls: 0.5803 - final_regr: 0.2930\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 10.328031809145129\n",
            "Classifier accuracy for bounding boxes from RPN: 0.75625\n",
            "Loss RPN classifier: 1.3798497622020636\n",
            "Loss RPN regression: 0.24141686367499643\n",
            "Loss Detector classifier: 0.5915617117392831\n",
            "Loss Detector regression: 0.28676130339852535\n",
            "Total loss: 2.499589641014868\n",
            "Elapsed time: 259.21233582496643\n",
            "Epoch 33/40\n",
            "1000/1000 [==============================] - 259s 259ms/step - rpn_cls: 1.3588 - rpn_regr: 0.2314 - final_cls: 0.6072 - final_regr: 0.2867\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 10.35253227408143\n",
            "Classifier accuracy for bounding boxes from RPN: 0.76275\n",
            "Loss RPN classifier: 1.3682691780907097\n",
            "Loss RPN regression: 0.2480224808822386\n",
            "Loss Detector classifier: 0.5922729384470731\n",
            "Loss Detector regression: 0.28413514809682966\n",
            "Total loss: 2.492699745516851\n",
            "Elapsed time: 259.0349419116974\n",
            "Epoch 34/40\n",
            "1000/1000 [==============================] - 256s 256ms/step - rpn_cls: 1.3350 - rpn_regr: 0.2368 - final_cls: 0.5960 - final_regr: 0.2886\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 10.703482587064677\n",
            "Classifier accuracy for bounding boxes from RPN: 0.7605\n",
            "Loss RPN classifier: 1.283850551151963\n",
            "Loss RPN regression: 0.2406648767008446\n",
            "Loss Detector classifier: 0.5956871335078031\n",
            "Loss Detector regression: 0.2816187153253704\n",
            "Total loss: 2.4018212766859808\n",
            "Elapsed time: 255.94771265983582\n",
            "Total loss decreased from 2.440047330104015 to 2.4018212766859808, saving weights\n",
            "Epoch 35/40\n",
            "1000/1000 [==============================] - 257s 257ms/step - rpn_cls: 1.3093 - rpn_regr: 0.2300 - final_cls: 0.5672 - final_regr: 0.2957\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 10.489043824701195\n",
            "Classifier accuracy for bounding boxes from RPN: 0.76125\n",
            "Loss RPN classifier: 1.2647499544865437\n",
            "Loss RPN regression: 0.23622221476538108\n",
            "Loss Detector classifier: 0.5663629914128687\n",
            "Loss Detector regression: 0.28450791780115103\n",
            "Total loss: 2.3518430784659445\n",
            "Elapsed time: 259.66836047172546\n",
            "Total loss decreased from 2.4018212766859808 to 2.3518430784659445, saving weights\n",
            "Epoch 36/40\n",
            "1000/1000 [==============================] - 261s 261ms/step - rpn_cls: 1.2651 - rpn_regr: 0.2613 - final_cls: 0.5538 - final_regr: 0.2901\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 10.263419483101393\n",
            "Classifier accuracy for bounding boxes from RPN: 0.76925\n",
            "Loss RPN classifier: 1.2593456215760799\n",
            "Loss RPN regression: 0.24650052540411707\n",
            "Loss Detector classifier: 0.5610366591401398\n",
            "Loss Detector regression: 0.28401429822505453\n",
            "Total loss: 2.3508971043453912\n",
            "Elapsed time: 264.2184615135193\n",
            "Total loss decreased from 2.3518430784659445 to 2.3508971043453912, saving weights\n",
            "Epoch 37/40\n",
            "1000/1000 [==============================] - 260s 260ms/step - rpn_cls: 1.3302 - rpn_regr: 0.2163 - final_cls: 0.5733 - final_regr: 0.2874\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 10.290547263681592\n",
            "Classifier accuracy for bounding boxes from RPN: 0.769\n",
            "Loss RPN classifier: 1.383039652012982\n",
            "Loss RPN regression: 0.2348900101785548\n",
            "Loss Detector classifier: 0.5573443611667026\n",
            "Loss Detector regression: 0.27876254654303195\n",
            "Total loss: 2.4540365699012714\n",
            "Elapsed time: 262.9259715080261\n",
            "Epoch 38/40\n",
            "1000/1000 [==============================] - 259s 259ms/step - rpn_cls: 1.2940 - rpn_regr: 0.2455 - final_cls: 0.5862 - final_regr: 0.2725\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 10.691468253968255\n",
            "Classifier accuracy for bounding boxes from RPN: 0.76875\n",
            "Loss RPN classifier: 1.3083898998389207\n",
            "Loss RPN regression: 0.24121204989604303\n",
            "Loss Detector classifier: 0.5617409848445095\n",
            "Loss Detector regression: 0.2738562675258145\n",
            "Total loss: 2.385199202105288\n",
            "Elapsed time: 258.61583852767944\n",
            "Epoch 39/40\n",
            "1000/1000 [==============================] - 255s 255ms/step - rpn_cls: 1.2556 - rpn_regr: 0.2238 - final_cls: 0.5739 - final_regr: 0.2695\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 10.530348258706468\n",
            "Classifier accuracy for bounding boxes from RPN: 0.759\n",
            "Loss RPN classifier: 1.2092360606468668\n",
            "Loss RPN regression: 0.22787814537470694\n",
            "Loss Detector classifier: 0.5671893009311753\n",
            "Loss Detector regression: 0.2683193695358932\n",
            "Total loss: 2.2726228764886427\n",
            "Elapsed time: 254.6771981716156\n",
            "Total loss decreased from 2.3508971043453912 to 2.2726228764886427, saving weights\n",
            "Epoch 40/40\n",
            " 484/1000 [=============>................] - ETA: 2:16 - rpn_cls: 1.2597 - rpn_regr: 0.2565 - final_cls: 0.5238 - final_regr: 0.2669Exception: 'a' cannot be empty unless no samples are taken\n",
            "1000/1000 [==============================] - 261s 261ms/step - rpn_cls: 1.2977 - rpn_regr: 0.2521 - final_cls: 0.5393 - final_regr: 0.2692\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 10.45382323733863\n",
            "Classifier accuracy for bounding boxes from RPN: 0.77125\n",
            "Loss RPN classifier: 1.3085495039956416\n",
            "Loss RPN regression: 0.24485190444940236\n",
            "Loss Detector classifier: 0.5504848271985538\n",
            "Loss Detector regression: 0.2677118096537888\n",
            "Total loss: 2.371598045297387\n",
            "Elapsed time: 263.9378228187561\n",
            "Training complete, exiting.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}